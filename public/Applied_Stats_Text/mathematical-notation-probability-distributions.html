<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Mathematical Notation, Probability, &amp; Distributions | Applied Statistics for the Ascendant Social Science Researcher: A Course Focused on Developing Skills, Building Confidence, and Not Being So Absolutely Confusing and Miserable</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Mathematical Notation, Probability, &amp; Distributions | Applied Statistics for the Ascendant Social Science Researcher: A Course Focused on Developing Skills, Building Confidence, and Not Being So Absolutely Confusing and Miserable" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Mathematical Notation, Probability, &amp; Distributions | Applied Statistics for the Ascendant Social Science Researcher: A Course Focused on Developing Skills, Building Confidence, and Not Being So Absolutely Confusing and Miserable" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Charles Marks" />


<meta name="date" content="2022-02-18" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="working-with-datasets-in-r.html"/>
<link rel="next" href="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Intro</a></li>
<li class="chapter" data-level="2" data-path="welcome.html"><a href="welcome.html"><i class="fa fa-check"></i><b>2</b> Welcome to R</a>
<ul>
<li class="chapter" data-level="2.1" data-path="welcome.html"><a href="welcome.html#in-this-chapter"><i class="fa fa-check"></i><b>2.1</b> In This Chapter</a></li>
<li class="chapter" data-level="2.2" data-path="welcome.html"><a href="welcome.html#downloading-r-and-rstudio"><i class="fa fa-check"></i><b>2.2</b> Downloading R and RStudio</a></li>
<li class="chapter" data-level="2.3" data-path="welcome.html"><a href="welcome.html#so-waitwhat-is-r"><i class="fa fa-check"></i><b>2.3</b> So, Wait…What is R?</a></li>
<li class="chapter" data-level="2.4" data-path="welcome.html"><a href="welcome.html#what-can-we-tell-the-computer-to-do-with-r"><i class="fa fa-check"></i><b>2.4</b> What can we tell the computer to do with R?</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="welcome.html"><a href="welcome.html#arithmetic"><i class="fa fa-check"></i><b>2.4.1</b> Arithmetic</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="welcome.html"><a href="welcome.html#saving-values"><i class="fa fa-check"></i><b>2.5</b> Saving Values</a></li>
<li class="chapter" data-level="2.6" data-path="welcome.html"><a href="welcome.html#types-of-data"><i class="fa fa-check"></i><b>2.6</b> Types of Data</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="welcome.html"><a href="welcome.html#numeric-data"><i class="fa fa-check"></i><b>2.6.1</b> Numeric Data</a></li>
<li class="chapter" data-level="2.6.2" data-path="welcome.html"><a href="welcome.html#character-data"><i class="fa fa-check"></i><b>2.6.2</b> Character Data</a></li>
<li class="chapter" data-level="2.6.3" data-path="welcome.html"><a href="welcome.html#logical-data"><i class="fa fa-check"></i><b>2.6.3</b> Logical Data</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="welcome.html"><a href="welcome.html#a-quick-check-in"><i class="fa fa-check"></i><b>2.7</b> A Quick Check-In</a></li>
<li class="chapter" data-level="2.8" data-path="welcome.html"><a href="welcome.html#storing-larger-quantities-of-data"><i class="fa fa-check"></i><b>2.8</b> Storing Larger Quantities of Data</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="welcome.html"><a href="welcome.html#vectors"><i class="fa fa-check"></i><b>2.8.1</b> Vectors</a></li>
<li class="chapter" data-level="2.8.2" data-path="welcome.html"><a href="welcome.html#data-frames"><i class="fa fa-check"></i><b>2.8.2</b> Data Frames</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="welcome.html"><a href="welcome.html#nice-job-everyone"><i class="fa fa-check"></i><b>2.9</b> Nice Job Everyone</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="functions.html"><a href="functions.html"><i class="fa fa-check"></i><b>3</b> Functions and Libraries</a>
<ul>
<li class="chapter" data-level="3.1" data-path="functions.html"><a href="functions.html#okay-waitwhats-a-function"><i class="fa fa-check"></i><b>3.1</b> Okay, wait…What’s a function?</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="functions.html"><a href="functions.html#a-real-world-example-of-a-function-buying-a-cake"><i class="fa fa-check"></i><b>3.1.1</b> A Real World Example of a Function: Buying a Cake</a></li>
<li class="chapter" data-level="3.1.2" data-path="functions.html"><a href="functions.html#picking-functions-in-r-the-read.csv-function"><i class="fa fa-check"></i><b>3.1.2</b> Picking Functions in R: The read.csv() function</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="functions.html"><a href="functions.html#breather-time"><i class="fa fa-check"></i><b>3.2</b> Breather Time</a></li>
<li class="chapter" data-level="3.3" data-path="functions.html"><a href="functions.html#looking-under-the-hood-writing-our-own-function"><i class="fa fa-check"></i><b>3.3</b> Looking Under the Hood: Writing Our Own Function</a></li>
<li class="chapter" data-level="3.4" data-path="functions.html"><a href="functions.html#so-whats-a-library"><i class="fa fa-check"></i><b>3.4</b> So What’s A Library?</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="functions.html"><a href="functions.html#how-do-i-see-what-is-in-my-library"><i class="fa fa-check"></i><b>3.4.1</b> How do I see what is in my library?</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="functions.html"><a href="functions.html#quick-word-of-caution"><i class="fa fa-check"></i><b>3.5</b> Quick word of caution</a></li>
<li class="chapter" data-level="3.6" data-path="functions.html"><a href="functions.html#in-conclusion"><i class="fa fa-check"></i><b>3.6</b> In Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="working-with-datasets-in-r.html"><a href="working-with-datasets-in-r.html"><i class="fa fa-check"></i><b>4</b> Working with Datasets in R</a>
<ul>
<li class="chapter" data-level="4.1" data-path="working-with-datasets-in-r.html"><a href="working-with-datasets-in-r.html#loading-a-dataset-into-r"><i class="fa fa-check"></i><b>4.1</b> Loading a Dataset into R</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="working-with-datasets-in-r.html"><a href="working-with-datasets-in-r.html#loading-other-formats-of-data"><i class="fa fa-check"></i><b>4.1.1</b> Loading Other Formats of Data</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="working-with-datasets-in-r.html"><a href="working-with-datasets-in-r.html#exploring-the-data"><i class="fa fa-check"></i><b>4.2</b> Exploring the Data</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="working-with-datasets-in-r.html"><a href="working-with-datasets-in-r.html#keep-your-codebook-handy"><i class="fa fa-check"></i><b>4.2.1</b> Keep Your Codebook Handy</a></li>
<li class="chapter" data-level="4.2.2" data-path="working-with-datasets-in-r.html"><a href="working-with-datasets-in-r.html#the-environment-pane"><i class="fa fa-check"></i><b>4.2.2</b> The Environment pane</a></li>
<li class="chapter" data-level="4.2.3" data-path="working-with-datasets-in-r.html"><a href="working-with-datasets-in-r.html#functions-for-exploring-and-cleaning-data"><i class="fa fa-check"></i><b>4.2.3</b> Functions for Exploring and Cleaning Data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="mathematical-notation-probability-distributions.html"><a href="mathematical-notation-probability-distributions.html"><i class="fa fa-check"></i><b>5</b> Mathematical Notation, Probability, &amp; Distributions</a>
<ul>
<li class="chapter" data-level="5.1" data-path="mathematical-notation-probability-distributions.html"><a href="mathematical-notation-probability-distributions.html#statistics-identifying-the-signal-from-the-noise"><i class="fa fa-check"></i><b>5.1</b> Statistics: Identifying the Signal From the Noise</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="mathematical-notation-probability-distributions.html"><a href="mathematical-notation-probability-distributions.html#statistics-and-falsification"><i class="fa fa-check"></i><b>5.1.1</b> Statistics and Falsification</a></li>
<li class="chapter" data-level="5.1.2" data-path="mathematical-notation-probability-distributions.html"><a href="mathematical-notation-probability-distributions.html#statistics-the-art-of-making-educated-guesses"><i class="fa fa-check"></i><b>5.1.2</b> Statistics: The Art of Making Educated Guesses</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="mathematical-notation-probability-distributions.html"><a href="mathematical-notation-probability-distributions.html#intro-to-probability-and-the-normal-distribution"><i class="fa fa-check"></i><b>5.2</b> Intro to Probability and the Normal Distribution</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="mathematical-notation-probability-distributions.html"><a href="mathematical-notation-probability-distributions.html#defining-probablity-mathematically"><i class="fa fa-check"></i><b>5.2.1</b> Defining Probablity Mathematically</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="mathematical-notation-probability-distributions.html"><a href="mathematical-notation-probability-distributions.html#conclusion"><i class="fa fa-check"></i><b>5.3</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html"><a href="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html"><i class="fa fa-check"></i><b>6</b> Scientific Research Questions and Null Hypothesis Significance Testing Framework</a>
<ul>
<li class="chapter" data-level="6.1" data-path="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html"><a href="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html#introduction"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html"><a href="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html#significance"><i class="fa fa-check"></i><b>6.2</b> “Significance”</a></li>
<li class="chapter" data-level="6.3" data-path="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html"><a href="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html#an-important-distinction-scientific-versus-statistical-hypotheses"><i class="fa fa-check"></i><b>6.3</b> An Important Distinction: Scientific Versus Statistical Hypotheses</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html"><a href="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html#scientific-research-questions-scientific-hypotheses"><i class="fa fa-check"></i><b>6.3.1</b> Scientific Research Questions &amp; Scientific Hypotheses</a></li>
<li class="chapter" data-level="6.3.2" data-path="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html"><a href="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html#statistical-hypotheses-the-null-and-the-alternate"><i class="fa fa-check"></i><b>6.3.2</b> Statistical Hypotheses: The Null and the Alternate</a></li>
<li class="chapter" data-level="6.3.3" data-path="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html"><a href="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html#answering-our-scientific-research-question-with-our-statistical-results"><i class="fa fa-check"></i><b>6.3.3</b> Answering Our Scientific Research Question with Our Statistical Results</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html"><a href="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html#a-look-at-history-to-understand-nhst"><i class="fa fa-check"></i><b>6.4</b> A Look At History To Understand NHST</a></li>
<li class="chapter" data-level="6.5" data-path="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html"><a href="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html#falsifying-the-null-hypothesis-say-hello-to-the-p-value"><i class="fa fa-check"></i><b>6.5</b> Falsifying the Null Hypothesis: Say Hello to the P-Value!</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html"><a href="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html#a-p-value-is-not"><i class="fa fa-check"></i><b>6.5.1</b> A P-Value is Not…</a></li>
<li class="chapter" data-level="6.5.2" data-path="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html"><a href="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html#lets-do-an-example-a-p-value-primer---big-babies"><i class="fa fa-check"></i><b>6.5.2</b> Let’s Do an Example: A P-Value Primer - Big Babies</a></li>
<li class="chapter" data-level="6.5.3" data-path="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html"><a href="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html#general-steps-to-calculating-p-value"><i class="fa fa-check"></i><b>6.5.3</b> General Steps to Calculating P-Value</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html"><a href="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html#but-there-must-be-an-alternative"><i class="fa fa-check"></i><b>6.6</b> But, There Must Be an Alternative</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html"><a href="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html#visualizing-the-null-and-the-alternate-an-example"><i class="fa fa-check"></i><b>6.6.1</b> Visualizing the Null and the Alternate, an example</a></li>
<li class="chapter" data-level="6.6.2" data-path="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html"><a href="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html#the-neyman-pearson-decision-matrix"><i class="fa fa-check"></i><b>6.6.2</b> The Neyman-Pearson Decision Matrix</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html"><a href="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html#putting-it-all-together-ish-null-hypothesis-significance-testing"><i class="fa fa-check"></i><b>6.7</b> Putting It All Together-ish: Null Hypothesis Significance Testing</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html"><a href="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html#so-nhst-isnt-a-good-idea"><i class="fa fa-check"></i><b>6.7.1</b> So, NHST Isn’t a Good Idea?</a></li>
<li class="chapter" data-level="6.7.2" data-path="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html"><a href="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html#misuse-of-nhst"><i class="fa fa-check"></i><b>6.7.2</b> Misuse of NHST</a></li>
<li class="chapter" data-level="6.7.3" data-path="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html"><a href="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html#what-should-i-do"><i class="fa fa-check"></i><b>6.7.3</b> What Should I Do?</a></li>
<li class="chapter" data-level="6.7.4" data-path="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html"><a href="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html#wading-through-the-meta-uncertainty-of-statistics"><i class="fa fa-check"></i><b>6.7.4</b> Wading Through The Meta-Uncertainty of Statistics</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html"><a href="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html#in-conclusion-1"><i class="fa fa-check"></i><b>6.8</b> In Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="descriptive-statistics-table-one.html"><a href="descriptive-statistics-table-one.html"><i class="fa fa-check"></i><b>7</b> Descriptive Statistics: Table One</a>
<ul>
<li class="chapter" data-level="7.1" data-path="descriptive-statistics-table-one.html"><a href="descriptive-statistics-table-one.html#sample-versus-population"><i class="fa fa-check"></i><b>7.1</b> Sample Versus Population</a></li>
<li class="chapter" data-level="7.2" data-path="descriptive-statistics-table-one.html"><a href="descriptive-statistics-table-one.html#inclusion-criteria"><i class="fa fa-check"></i><b>7.2</b> Inclusion Criteria</a></li>
<li class="chapter" data-level="7.3" data-path="descriptive-statistics-table-one.html"><a href="descriptive-statistics-table-one.html#the-sample-does-not-always-match-the-population"><i class="fa fa-check"></i><b>7.3</b> The Sample Does Not Always Match the Population</a></li>
<li class="chapter" data-level="7.4" data-path="descriptive-statistics-table-one.html"><a href="descriptive-statistics-table-one.html#introducing-table-one"><i class="fa fa-check"></i><b>7.4</b> Introducing: Table One!</a></li>
<li class="chapter" data-level="7.5" data-path="descriptive-statistics-table-one.html"><a href="descriptive-statistics-table-one.html#rewind-a-bit-what-exactly-are-descriptive-statistics"><i class="fa fa-check"></i><b>7.5</b> Rewind a Bit: What Exactly are Descriptive Statistics</a></li>
<li class="chapter" data-level="7.6" data-path="descriptive-statistics-table-one.html"><a href="descriptive-statistics-table-one.html#primary-types-of-descriptives-seen-in-table-one"><i class="fa fa-check"></i><b>7.6</b> Primary Types of Descriptives Seen in Table One</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="descriptive-statistics-table-one.html"><a href="descriptive-statistics-table-one.html#descriptive-statistics-for-categorical-data"><i class="fa fa-check"></i><b>7.6.1</b> Descriptive Statistics for Categorical Data</a></li>
<li class="chapter" data-level="7.6.2" data-path="descriptive-statistics-table-one.html"><a href="descriptive-statistics-table-one.html#descriptive-statistics-for-numeric-data"><i class="fa fa-check"></i><b>7.6.2</b> Descriptive Statistics for Numeric Data</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="descriptive-statistics-table-one.html"><a href="descriptive-statistics-table-one.html#creating-table-one"><i class="fa fa-check"></i><b>7.7</b> Creating Table One</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="descriptive-statistics-table-one.html"><a href="descriptive-statistics-table-one.html#the-tableone-package"><i class="fa fa-check"></i><b>7.7.1</b> The tableone package</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="descriptive-statistics-table-one.html"><a href="descriptive-statistics-table-one.html#in-conclusion-2"><i class="fa fa-check"></i><b>7.8</b> In Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="comparing-two-groups-w-independent-samples-t-test.html"><a href="comparing-two-groups-w-independent-samples-t-test.html"><i class="fa fa-check"></i><b>8</b> Comparing Two Groups w/ Independent Samples T-test</a>
<ul>
<li class="chapter" data-level="8.1" data-path="comparing-two-groups-w-independent-samples-t-test.html"><a href="comparing-two-groups-w-independent-samples-t-test.html#statistical-hypotheses-of-the-independent-samples-t-test"><i class="fa fa-check"></i><b>8.1</b> Statistical Hypotheses of the Independent Samples T-Test</a></li>
<li class="chapter" data-level="8.2" data-path="comparing-two-groups-w-independent-samples-t-test.html"><a href="comparing-two-groups-w-independent-samples-t-test.html#logic-of-the-t-test"><i class="fa fa-check"></i><b>8.2</b> Logic of the t-test</a></li>
<li class="chapter" data-level="8.3" data-path="comparing-two-groups-w-independent-samples-t-test.html"><a href="comparing-two-groups-w-independent-samples-t-test.html#introducing-the-students-t-distribution"><i class="fa fa-check"></i><b>8.3</b> Introducing the Student’s t-Distribution</a></li>
<li class="chapter" data-level="8.4" data-path="comparing-two-groups-w-independent-samples-t-test.html"><a href="comparing-two-groups-w-independent-samples-t-test.html#mapping-the-signal-onto-the-t-distribution"><i class="fa fa-check"></i><b>8.4</b> Mapping The Signal Onto The t-Distribution</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="comparing-two-groups-w-independent-samples-t-test.html"><a href="comparing-two-groups-w-independent-samples-t-test.html#calculating-the-standard-error-of-the-mean"><i class="fa fa-check"></i><b>8.4.1</b> Calculating the Standard Error of the Mean</a></li>
<li class="chapter" data-level="8.4.2" data-path="comparing-two-groups-w-independent-samples-t-test.html"><a href="comparing-two-groups-w-independent-samples-t-test.html#calculating-our-test-statistic-t"><i class="fa fa-check"></i><b>8.4.2</b> Calculating our test statistic, t</a></li>
<li class="chapter" data-level="8.4.3" data-path="comparing-two-groups-w-independent-samples-t-test.html"><a href="comparing-two-groups-w-independent-samples-t-test.html#two-tailed-versus-one-tailed-t-test"><i class="fa fa-check"></i><b>8.4.3</b> Two-Tailed Versus One-Tailed T-Test</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="comparing-two-groups-w-independent-samples-t-test.html"><a href="comparing-two-groups-w-independent-samples-t-test.html#three-variations-of-the-t-test"><i class="fa fa-check"></i><b>8.5</b> Three Variations of the <span class="math inline">\(t\)</span>-test</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="comparing-two-groups-w-independent-samples-t-test.html"><a href="comparing-two-groups-w-independent-samples-t-test.html#independent-samples-t-test"><i class="fa fa-check"></i><b>8.5.1</b> Independent Samples t-test</a></li>
<li class="chapter" data-level="8.5.2" data-path="comparing-two-groups-w-independent-samples-t-test.html"><a href="comparing-two-groups-w-independent-samples-t-test.html#one-sample-t-test"><i class="fa fa-check"></i><b>8.5.2</b> One Sample <span class="math inline">\(t\)</span>-test</a></li>
<li class="chapter" data-level="8.5.3" data-path="comparing-two-groups-w-independent-samples-t-test.html"><a href="comparing-two-groups-w-independent-samples-t-test.html#paired-samples-t-test"><i class="fa fa-check"></i><b>8.5.3</b> Paired Samples <span class="math inline">\(t\)</span>-test</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="comparing-two-groups-w-independent-samples-t-test.html"><a href="comparing-two-groups-w-independent-samples-t-test.html#what-are-the-assumptions-we-make-prior-to-running-an-independent-samples-t-test"><i class="fa fa-check"></i><b>8.6</b> What Are the Assumptions We Make Prior to Running an Independent Samples T-test</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="comparing-two-groups-w-independent-samples-t-test.html"><a href="comparing-two-groups-w-independent-samples-t-test.html#assumption-1-our-variable-of-interest-x-must-be-measured-on-an-ordinal-or-continuous-scale"><i class="fa fa-check"></i><b>8.6.1</b> Assumption #1: Our Variable of Interest, <span class="math inline">\(X\)</span>, Must Be Measured on an Ordinal or Continuous Scale</a></li>
<li class="chapter" data-level="8.6.2" data-path="comparing-two-groups-w-independent-samples-t-test.html"><a href="comparing-two-groups-w-independent-samples-t-test.html#assumption-2-data-must-be-drawn-from-a-random-sample"><i class="fa fa-check"></i><b>8.6.2</b> Assumption #2: Data Must Be Drawn From a Random Sample</a></li>
<li class="chapter" data-level="8.6.3" data-path="comparing-two-groups-w-independent-samples-t-test.html"><a href="comparing-two-groups-w-independent-samples-t-test.html#assumption-3-normality-of-observations-of-x"><i class="fa fa-check"></i><b>8.6.3</b> Assumption #3: Normality of Observations of <span class="math inline">\(X\)</span></a></li>
<li class="chapter" data-level="8.6.4" data-path="comparing-two-groups-w-independent-samples-t-test.html"><a href="comparing-two-groups-w-independent-samples-t-test.html#assumption-4-homogeneity-of-variance"><i class="fa fa-check"></i><b>8.6.4</b> Assumption #4: Homogeneity of Variance</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="comparing-two-groups-w-independent-samples-t-test.html"><a href="comparing-two-groups-w-independent-samples-t-test.html#last-but-not-least---how-do-we-run-a-t-test-in-r"><i class="fa fa-check"></i><b>8.7</b> Last But Not Least - How Do We Run A t-Test in R</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="pearsons-chi2-test.html"><a href="pearsons-chi2-test.html"><i class="fa fa-check"></i><b>9</b> Pearson’s <span class="math inline">\(\chi^2\)</span> Test</a>
<ul>
<li class="chapter" data-level="9.1" data-path="pearsons-chi2-test.html"><a href="pearsons-chi2-test.html#expectations-v.-observations"><i class="fa fa-check"></i><b>9.1</b> Expectations v. Observations</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="pearsons-chi2-test.html"><a href="pearsons-chi2-test.html#income-level-and-smoking-status"><i class="fa fa-check"></i><b>9.1.1</b> Income Level and Smoking Status</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="pearsons-chi2-test.html"><a href="pearsons-chi2-test.html#the-chi2-distribution"><i class="fa fa-check"></i><b>9.2</b> The <span class="math inline">\(\chi^2\)</span> Distribution</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="pearsons-chi2-test.html"><a href="pearsons-chi2-test.html#the-chi_k2-distribution-with-k-degrees-of-freedom"><i class="fa fa-check"></i><b>9.2.1</b> The <span class="math inline">\(\chi_k^2\)</span> Distribution with <span class="math inline">\(k\)</span> Degrees of Freedom</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="pearsons-chi2-test.html"><a href="pearsons-chi2-test.html#the-chi2-test-of-independence"><i class="fa fa-check"></i><b>9.3</b> The <span class="math inline">\(\chi^2\)</span> Test of Independence</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="pearsons-chi2-test.html"><a href="pearsons-chi2-test.html#formally-defining-the-test"><i class="fa fa-check"></i><b>9.3.1</b> Formally Defining the Test</a></li>
<li class="chapter" data-level="9.3.2" data-path="pearsons-chi2-test.html"><a href="pearsons-chi2-test.html#what-are-the-assumptions-of-the-chi2-test-of-independence"><i class="fa fa-check"></i><b>9.3.2</b> What are the assumptions of the <span class="math inline">\(\chi^2\)</span> Test of Independence</a></li>
<li class="chapter" data-level="9.3.3" data-path="pearsons-chi2-test.html"><a href="pearsons-chi2-test.html#running-the-chi2-test-in-r"><i class="fa fa-check"></i><b>9.3.3</b> Running the <span class="math inline">\(\chi^2\)</span> Test in R</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="pearsons-chi2-test.html"><a href="pearsons-chi2-test.html#other-variations-of-the-chi2-test"><i class="fa fa-check"></i><b>9.4</b> Other Variations of the <span class="math inline">\(\chi^2\)</span> Test</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="pearsons-chi2-test.html"><a href="pearsons-chi2-test.html#goodness-of-fit-test"><i class="fa fa-check"></i><b>9.4.1</b> Goodness of Fit Test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="covariance-and-correlation.html"><a href="covariance-and-correlation.html"><i class="fa fa-check"></i><b>10</b> Covariance and Correlation</a>
<ul>
<li class="chapter" data-level="10.1" data-path="covariance-and-correlation.html"><a href="covariance-and-correlation.html#covariance"><i class="fa fa-check"></i><b>10.1</b> Covariance</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="covariance-and-correlation.html"><a href="covariance-and-correlation.html#measuring-covariance"><i class="fa fa-check"></i><b>10.1.1</b> Measuring Covariance</a></li>
<li class="chapter" data-level="10.1.2" data-path="covariance-and-correlation.html"><a href="covariance-and-correlation.html#covariance-is-a-measure-of-association"><i class="fa fa-check"></i><b>10.1.2</b> Covariance is a Measure of Association</a></li>
<li class="chapter" data-level="10.1.3" data-path="covariance-and-correlation.html"><a href="covariance-and-correlation.html#measuring-and-visualizing-covariance-in-r"><i class="fa fa-check"></i><b>10.1.3</b> Measuring and Visualizing Covariance in R</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="covariance-and-correlation.html"><a href="covariance-and-correlation.html#correlation"><i class="fa fa-check"></i><b>10.2</b> Correlation</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="covariance-and-correlation.html"><a href="covariance-and-correlation.html#computing-the-correlation-coefficient-for-a-sample"><i class="fa fa-check"></i><b>10.2.1</b> Computing the Correlation Coefficient for a Sample</a></li>
<li class="chapter" data-level="10.2.2" data-path="covariance-and-correlation.html"><a href="covariance-and-correlation.html#computing-the-coefficient-in-r"><i class="fa fa-check"></i><b>10.2.2</b> Computing the Coefficient in R</a></li>
<li class="chapter" data-level="10.2.3" data-path="covariance-and-correlation.html"><a href="covariance-and-correlation.html#interpreting-the-correlation-coefficient"><i class="fa fa-check"></i><b>10.2.3</b> Interpreting the Correlation Coefficient</a></li>
<li class="chapter" data-level="10.2.4" data-path="covariance-and-correlation.html"><a href="covariance-and-correlation.html#what-if-the-correlation-between-two-variables-is-not-linear-in-nature"><i class="fa fa-check"></i><b>10.2.4</b> What if the Correlation Between Two Variables Is Not Linear in Nature</a></li>
<li class="chapter" data-level="10.2.5" data-path="covariance-and-correlation.html"><a href="covariance-and-correlation.html#correlation-matrix"><i class="fa fa-check"></i><b>10.2.5</b> Correlation Matrix</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Applied Statistics for the Ascendant Social Science Researcher: A Course Focused on Developing Skills, Building Confidence, and Not Being So Absolutely Confusing and Miserable</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="mathematical-notation-probability-distributions" class="section level1" number="5">
<h1><span class="header-section-number">Chapter 5</span> Mathematical Notation, Probability, &amp; Distributions</h1>
<p>Before we dive into learning and applying statistical tools, we need to learn about some important concepts.</p>
<p>This week, we will discuss how statistics is all about assessing probability. Further, we will formally introduce some mathematical language we can use to discuss probability and we will introduce theoretical distributions and how we can use them to think about probability. In this text, we will specifically focus on introducing and understanding the normal distribution, one of the most important distributions in the field of statistics.</p>
<div id="statistics-identifying-the-signal-from-the-noise" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Statistics: Identifying the Signal From the Noise</h2>
<p>One of the primary goals in this class is to help get you comfortable with inferential statistics techniques. <strong>Inferential</strong> statistics are methods where we take data from a <strong>sample</strong> of <span class="math inline">\(n\)</span> people and then try to learn something about the broader <strong>population</strong> of people we think they represent. When we talk about an arbitrary number of people, we will often use the the letter <span class="math inline">\(n\)</span> when we don’t know what that number actually is (or when the exact amount doesn’t matter). A <strong>population</strong> represents a broad category of people we want to learn about and a <strong>sample</strong> represents a subset of that population that we recruited for a study.</p>
<p>The reason inferential statistics are so important is because usually you cannot survey every person in a population of interest. Perhaps you want to do a study focusing on people who vape in the United States - well, that is quite literally millions of people. Surveying millions of people is impractical or impossible. However, it is more practical to recruit <span class="math inline">\(n = 1,000\)</span> people who vape or <span class="math inline">\(n = 10,000\)</span> people who vape. With inferential statistics methods, we can take information about our sample of <span class="math inline">\(n\)</span> people who vape and try to make conclusions about the broader population of people who vape. This is our main mission when employing inferential statistics techniques - take information from a sample to learn about a corresponding population.</p>
<p>These inferential “conclusions” are essentially probabalistic guesses! These methods allow us to ask, “How probable do we think it is that the <strong>signal</strong> we have observed in our sample is representative of the broader population?” Here, <strong>signal</strong> just refers to any effect or difference that we may observe. For example, in our (hypothetical) study of people who vape, we might find that twice as many men in the sample report using their vape while at work compared to women in the sample. This difference between men and women in the sample represents a <strong>signal</strong> - the objective of inferential statistical methods is to help us determine how probable we think it is that the signal within the sample represents a meaningful, <strong>non-random</strong> pattern within the overall population. In the case of our example, how probable do we think it is that men who vape are actually more likley than women who vape to vape while they are at work?</p>
<p>One of the hardest parts about trying to identify these <strong>signals</strong> is wading through the <strong>noise</strong> in our data. We can think of <strong>noise</strong> as variability within our data that is simply the result of <strong>randomness</strong>. Even if there exists a signal in our overall population, when we run a study we intend to recruit a <strong>random</strong> sample - a sample is considered <strong>random</strong> when every person in the population has the same probability of being chosen. This randomness introduces variability into the data that may obscure signals we might observe.</p>
<p>For example, let’s say we want to know how likely it is that if we flip a coin we get heads. Intuitively, we imagine it is 50-50, that 50% of all coin flips should be heads and 50% should be tails. So, we flip a coin once and get heads. We flip it again and get…heads?!?! In fact we flip 5 heads in a row before we get a tails! We flip the coin 100 hundred times and we end up flipping heads 72 times. Now, I promise you, the reader, that there is a 50% chance of getting heads (assuming this isn’t some trick coin or some quantum thought experiment), however, because every coin flip is independent (i.e., not dependent on any other coin flip) and <strong>random</strong>, the reality is that we have flipped heads 72% of the time! This represents our <strong>signal</strong>. Because we have taken a random sample of coin flips, there is natural variation in the results we have observed - this variation is the <strong>noise</strong>. <strong>Noise</strong>, natural variation in our sample data as a result of randomness, obscures the <strong>signals</strong> that can tell us about our population.</p>
<p>So, our goal in inferential statistics is to take a sample and try to learn something about the population we believe they represent. In order to do so, we must wade through noisy data in search of meaningful, probable signals. While by no means a rigorous equation, our ability to make conclusions about the population is dependent on the ratio of signal to noise, or: <span class="math inline">\(\frac{signal}{noise}\)</span>. Often we assume that no signal exists at the population-level and then try to assess how probable our observed data is under this assumption.</p>
<p>With a fraction, a big numerator (i.e., the top) means the overall number is bigger (i.e., <span class="math inline">\(\frac{4}{3} &gt; \frac{2}{3}\)</span>). A bigger denominator (i.e., the bottom) means the overall number is smaller (i.e., <span class="math inline">\(\frac{2}{5} &lt; \frac{2}{3}\)</span>). So, we can understand that the bigger (or “stronger”) our signal in our sample, the less probable we think it is that no signal exists at the population-level (or, the more probable we think it is that a signal does exist). Noise can be understood to obscure signals we may observe in our data (i.e., weaken signals)</p>
<div id="statistics-and-falsification" class="section level3" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> Statistics and Falsification</h3>
<p>So, statistics represents a broad set of methods through which we can take data from a sample, search for signals amidst the random noise, and assess how probable we think it is that the signal we are observing is representative of the broader population! Importantly, statistics isn’t about figuring out what is <strong>true</strong> or <strong>false</strong>. Statistical methods were developed because we really cannot know what is true – instead we can reflect on what is probable. If something is not probable, we could assume some alternate reality is true, a sort of logic of contradiction. We refer to the act of determining something is improbable as <strong>falsification</strong>. For example, we could never prove that men vape at work more than women do, but we could observe data and feel confident that it is probable that men and women don’t vape the same amount at work - we can seek to falsify that possibility by examing our data.</p>
<p>In statistics we do this by assuming a signal does not exist and then asking how probable our observed data is under this assumption - a confirmation by contradiction, of sorts. For example, we could assume that men and women who vape, vape the same amount at work. Then we could collect data and ask, “if we assume that men and women vape the same amount at work, how likely is the data we have observed?” Let’s say we collect data about vaping at work and find that men vape at work 2% more than women - if we assume that men and women, generally, vape the same amount of work, does this signal in our sample seem probable? Sure! - 2% doesn’t seem like a very big difference. Maybe we just happened to interview a couple men who vape at work a lot (e.g., noise). Or, what if in our sample, men smoke at work 300% more than women? This observation seems way more unlikely if we assume no true signal and we feel more confident rejecting our assumption that men and women vape the same amount at work! This is the logic we will be employing when we use inferential statistics techniques - we will assume that a signal doesn’t exist and then observe data and assess how probable our observed data is under our assumption of no signal.</p>
<p>This represents a logic of contradiction. We make an assumption and then ask how likely our observation are under that assumption. If the observations are unlikely, this provides evidence that our assumption may be wrong and then we reject our assumption. Almost every inferential statistical test involves three primary steps: the first is to assume that a signal does not exist in the overall population (e.g., assume that men do not vape at work more than women do); the second is then to measure and quantify the signal and the noise within the sample; and the final step is to ask how probable it is that we could observe the patterns in our data assuming that no such signal exists. To apply this to our coin flipping scenario: first, we assume that there is a 50% chance of flipping heads any flip; then we flip a coin <span class="math inline">\(n\)</span> times and calculate how often we got heads; and, finally, based on the data, we ask how probable it is that we could have observed the sample (i.e., the coin flips) assuming that the chances of flipping a heads was 50-50. So, if we flip a coin 100 times and get heads 72 times, do we still feel confident that there is a 50% chance of getting heads?</p>
</div>
<div id="statistics-the-art-of-making-educated-guesses" class="section level3" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> Statistics: The Art of Making Educated Guesses</h3>
<p>Perhaps this was all a long-winded way of saying that statistics is the art of making educated guesses based on the data we have available to us. This is, in fact, a very human activity! We do it all the time! Every day we make probabalistic decisions based on information available to us. A classic example is which way should I drive home to avoid traffic? You usually can’t know the best way, but from experience (your sample), you decide the route (usually dependent on the time of day and which routes are available). You choose the route you think has the highest probablity of being fastest.</p>
<p>Now, statistics can feel scary because it is often presented as a bunch of mathematical equations and weird distributions and there are lots of Greek letters and tables. I definitely don’t whip out a calculator and do some mathematical calculations to decide which way to drive home (even Google Maps cannot predict a car crash before it happens). In this chapter, I want to go over some of this “scary” math stuff because its all just ways of presenting probability in formal and testable terms. So, as we dive in, I want to assure you that you are familiar with the logic behind probability - understanding how we represent probablity and probabilistic decision-making in statistics will actually make understanding the statistical methods way way way easier.</p>
</div>
</div>
<div id="intro-to-probability-and-the-normal-distribution" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Intro to Probability and the Normal Distribution</h2>
<p>Statistics is all about assessing the probability of our observed data given some assumption. As such, we need ways to formally think through the concepts of probablity.</p>
<div id="defining-probablity-mathematically" class="section level3" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> Defining Probablity Mathematically</h3>
<p>We need a way to express the following question mathematically: “What is the probability that [insert phenomenon] will occur?” For example, we might wish to ask, what is the probability that the result of our next coin flip will be heads? If we let <span class="math inline">\(A\)</span> represent our next coin flip, we then want to ask, “What is the probability that <span class="math inline">\(A = heads\)</span>?”</p>
<p>We can use <span class="math inline">\(P(x)\)</span> notation to achieve this statement mathematically. <span class="math inline">\(P(x)\)</span> can simply be translated as “The probablity of <span class="math inline">\(x\)</span>….” So, if we were to write <span class="math inline">\(P(A = heads)\)</span>, we would read that as saying that “The probability that our next coin flip will be heads is….” Intuitively, we know that <span class="math inline">\(P(A = heads) = .5 = 50\%\)</span>. We would read this as saying “The probability that our next coin flip is heads equals 50%.”</p>
<p>We can also chain together multiple phenomena and ask how likely the combination of outcomes is. For example, we could ask <span class="math inline">\(P(A = heads\)</span> <span class="math inline">\(OR\)</span> <span class="math inline">\(A = tails)\)</span>. Here we are just asking what the probability is that the coin flip will be either heads or tails - we can see that since those are the only possibilities for a normal coin that <span class="math inline">\(P(A = heads\)</span> <span class="math inline">\(OR\)</span> <span class="math inline">\(A = tails) = 1 = 100\%\)</span>.</p>
<div id="conditional-probablity" class="section level4" number="5.2.1.1">
<h4><span class="header-section-number">5.2.1.1</span> Conditional Probablity</h4>
<p>At the heart of inferential statistics is the concept of conditional probablity. Conditional probability comes in handy when we want to ask, “Assuming that <span class="math inline">\(A\)</span> is true, what is the probablity of <span class="math inline">\(B\)</span> occurring?” Here <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> simply represent phenomenon or circumstances.</p>
<p>We can write this mathematically, like so: <span class="math inline">\(P(B|A)\)</span>. We would read this as “The probability of <span class="math inline">\(B\)</span>, given that <span class="math inline">\(A\)</span> is true….” Now, <span class="math inline">\(A\)</span> does not actually have to be true, it can be entirely hypothetical. For example, someone could ask you if the freeway is the fastest route to get to your house - let <span class="math inline">\(B\)</span> represent the freeway route to your home. Now, (hypothetically) you know that the freeway is the fastest way except during rush hour. During rush hour, you have found that the freeway is fastest only 1/3 of the time. So, let <span class="math inline">\(A\)</span> represent whether or not it is rush hour. We could ask <span class="math inline">\(P(B|A = not\)</span> <span class="math inline">\(rush\)</span> <span class="math inline">\(hour)\)</span>. Well, from experience we have found that the freeway is always fastest when it is not rush hour so, <span class="math inline">\(P(B|A = not\)</span> <span class="math inline">\(rush\)</span> <span class="math inline">\(hour) = 1 = 100\%\)</span>. Likewise we could ask <span class="math inline">\(P(B|A = rush\)</span> <span class="math inline">\(hour)\)</span>. From experience, we have found that <span class="math inline">\(P(B|A = rush\)</span> <span class="math inline">\(hour) = 1/3 = 33.\bar{3}\%\)</span>.</p>
<p>Why is conditional probability so important in inferential statistics? In a quantitative study, we will observe some data (i.e., our study sample). We will also assume that a signal does not exist (e.g., men and women who vape, vape the same amount at work). So, we will try to ask <span class="math inline">\(P(data|no\)</span> <span class="math inline">\(signal)\)</span> - or, what is the probablity that we observed our data assuming that no signal exists? That is the foundation of every single inferential statistical method that we will employ, for example:</p>
<blockquote>
<p>If we want to know if smoking cigarettes leads to lung cancer, we would 1) assume that smoking cigarettes and lung cancer are not related, 2) observe data from a sample (perhaps ask people if they smoked and if they had lung cancer), and 3) then assess how probable our data is given our assumption that smoking cigarettes and lung cancer are not related.</p>
</blockquote>
<p>The “probablity of data” seems like a funny concept. Let us say we assume that men and women who vape do so the same amount at work. We recurit a sample and ask how often they vape at work and then we compare responses of men and women. If we assume that men and women vape the same amount at work, then we imagine it is quite probable that men and women report vaping at work at similar rates. However, it’s almost certain that men and women in our sample won’t have identical vaping patterns at work - thus, it is important that we be able to capture probabilties of discrepancies between our observed data and our assumption. For example, if we think that men and women vape the same amount at work, it seems that it would be quite probable that in our sample we find that men, on average, vape at work 0.2 times more per workday than women - perhaps we randomly sampled a couple of men who vape more than others. Whereas, it might be quite <em>improbable</em>, assuming men and women vape the same amount, if we found that men vape 10 times more per workday than women - such an improbable finding might force us to question if our initial assumption was correct. So, we need a way to assess the probability of our data given some underlying assumption.</p>
</div>
<div id="introducing-theoretical-probability-distributions" class="section level4" number="5.2.1.2">
<h4><span class="header-section-number">5.2.1.2</span> Introducing Theoretical Probability Distributions</h4>
<p>We do so by employing theoretical probability distributions. A probability distribution is a mathematical function that identifies the probability of a given outcome occurring. While distributions are sometimes a primary point of confusion in statistics, the reality is that distributions are just a way of capturing the way we think about probabilities - they first come from our intuition about the world, the math is just a way of making it rigorous. Essentially, a probability distribution is a tool by which we can make assumptions about the behavior of a given variable.</p>
<p>For example, let’s imagine we are playing a game where we are guessing the height of the next person to walk in the room - we don’t have any information prior to making our guess. Well, our best guess is probably the average height of all people…let’s say we are pretty sure the average person is 5 foot 8 inches tall. We are also pretty sure that there are just as many people shorter than 5’8" as there are taller than 5’8" (i.e., the distribution of height is symmetrical around the mean). Further, we are quite positive that most people’s heights are around 5’8" - we feel confident that most people are between 5’2" and 6’2". It is quite rare for someone to be shorter than or taller than that range.</p>
<p>So, we have constructed a theory of the distribution of height in order to play this game. We think that if someone walks into the room (i.e., a random observation), that they are most likely to be of average height (5’8“) or close to that height (whether taller or shorter). Further, we think that heights far away (way shorter or way taller) than 5’8” are the least likely to be observed. We can actually capture this probability by plotting it as a mathematical function like so. We will have the x-axis be height (in inches) and the y-axis will represent the hypothetical probability of observing that height if someone walked in the door:</p>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb176-1"><a href="mathematical-notation-probability-distributions.html#cb176-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Let&#39;s create our x-axis, ranging from 4&#39;4&quot; (52 inches) to 7&#39;0&quot; (84 inches)</span></span>
<span id="cb176-2"><a href="mathematical-notation-probability-distributions.html#cb176-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">52</span>, <span class="dv">84</span>, <span class="at">by =</span> .<span class="dv">1</span>)</span>
<span id="cb176-3"><a href="mathematical-notation-probability-distributions.html#cb176-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb176-4"><a href="mathematical-notation-probability-distributions.html#cb176-4" aria-hidden="true" tabindex="-1"></a><span class="do">## We will define probabilities using the dnorm function</span></span>
<span id="cb176-5"><a href="mathematical-notation-probability-distributions.html#cb176-5" aria-hidden="true" tabindex="-1"></a><span class="do">## The dnorm function generates the points that correspond to a normal distribution</span></span>
<span id="cb176-6"><a href="mathematical-notation-probability-distributions.html#cb176-6" aria-hidden="true" tabindex="-1"></a><span class="do">## We will set the average height to 5&#39;8&quot; (68 inches) with a standard deviation of 4 inches</span></span>
<span id="cb176-7"><a href="mathematical-notation-probability-distributions.html#cb176-7" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(x, <span class="at">mean =</span> <span class="dv">68</span>, <span class="at">sd =</span> <span class="dv">4</span>)</span>
<span id="cb176-8"><a href="mathematical-notation-probability-distributions.html#cb176-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb176-9"><a href="mathematical-notation-probability-distributions.html#cb176-9" aria-hidden="true" tabindex="-1"></a><span class="do">## We will now plot the normally distributed data as a line (type = &quot;l&quot;)</span></span>
<span id="cb176-10"><a href="mathematical-notation-probability-distributions.html#cb176-10" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,y, <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;Height in Inches&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Density&quot;</span>)</span></code></pre></div>
<p><img src="Intro-to-Applied-Stats-with-R_files/figure-html/unnamed-chunk-75-1.png" width="672" /></p>
<p>As we can see, this mathematical function represents our idea of the distribution of height among a random sample (i.e., the people walking in the door). The height of the curve represents how likely we believe it is that that value will be observed. We can see that 68 inches is the most probable height to observe (it is the tallest point of the curve), that heights nearer to 5’8" are relatively likely, and that heights further away from 5’8" are rarer. Further, we don’t have any reason to think there are more short people than tall, or vice versa, so the distribution is symmetrical around the mean.</p>
<p>This curve is referred to as the <strong>normal distribution</strong> and it is the first and most important distribution we will encounter in our statistics work. We will often assume that an outcome follows the normal distribution. So, as we can see, this normal distribution sort of captures our intuition around how we believe height is distributed amongst the population.</p>
</div>
<div id="assessing-probabilities-using-theoretical-distributions" class="section level4" number="5.2.1.3">
<h4><span class="header-section-number">5.2.1.3</span> Assessing Probabilities Using Theoretical Distributions</h4>
<p>One of the really cool parts of theoretical probability distributions is that we can ask how probable a range of outcomes are, assuming that the distribution is correct. We may wish to know how likely it is that someone 6’6" inches or taller walks in the door! Importantly, we can agree that if someone walks through the door, there is a 100% that they will have a height! That might be silly to say, but since the height of the distribution curve represents the probability of observing that given value, that means that if you sum together the height of the curve at every point, that the sum will add up to exactly 1 (which corresponds to 100%). We can depict this using the concept of <strong>area under the curve</strong>. We can depict the area under the curve like so:</p>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb177-1"><a href="mathematical-notation-probability-distributions.html#cb177-1" aria-hidden="true" tabindex="-1"></a><span class="do">## We will now plot the normally distributed data as a line (type = &quot;l&quot;)</span></span>
<span id="cb177-2"><a href="mathematical-notation-probability-distributions.html#cb177-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,y, <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;Height in Inches&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Density&quot;</span>)</span>
<span id="cb177-3"><a href="mathematical-notation-probability-distributions.html#cb177-3" aria-hidden="true" tabindex="-1"></a><span class="fu">polygon</span>(x,y,<span class="at">col =</span> <span class="st">&quot;slateblue1&quot;</span>)</span></code></pre></div>
<p><img src="Intro-to-Applied-Stats-with-R_files/figure-html/unnamed-chunk-76-1.png" width="672" /></p>
<p>The sum of the shaded region of the plot in this case is exactly 1. We can actually calculate this using the auc function in the MESS library.</p>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb178-1"><a href="mathematical-notation-probability-distributions.html#cb178-1" aria-hidden="true" tabindex="-1"></a><span class="do">## First we take the integral of our curve using the AUC function in the MESS library</span></span>
<span id="cb178-2"><a href="mathematical-notation-probability-distributions.html#cb178-2" aria-hidden="true" tabindex="-1"></a><span class="do">## AUC stands for &quot;Area Under the Curve&quot;</span></span>
<span id="cb178-3"><a href="mathematical-notation-probability-distributions.html#cb178-3" aria-hidden="true" tabindex="-1"></a>AUC <span class="ot">&lt;-</span> MESS<span class="sc">::</span><span class="fu">auc</span>(x,y)</span>
<span id="cb178-4"><a href="mathematical-notation-probability-distributions.html#cb178-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb178-5"><a href="mathematical-notation-probability-distributions.html#cb178-5" aria-hidden="true" tabindex="-1"></a><span class="do">## We will round the result to two decimal for ease of reading</span></span>
<span id="cb178-6"><a href="mathematical-notation-probability-distributions.html#cb178-6" aria-hidden="true" tabindex="-1"></a><span class="do">## Taking integrals of lines is an imperfect art so R doesn&#39;t get exactly 1</span></span>
<span id="cb178-7"><a href="mathematical-notation-probability-distributions.html#cb178-7" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(AUC,<span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 1</code></pre>
<p>Now, this isn’t super interesting. Of course there is a 100% chance that a person has a height. But, now we can start asking more interesting questions. If <span class="math inline">\(X\)</span> is the height of the next person to walk in to the room, we could ask <span class="math inline">\(P(X &gt;= 5&#39;8&quot; | height\)</span> <span class="math inline">\(is\)</span> <span class="math inline">\(normally\)</span> <span class="math inline">\(distributed)\)</span> (or what is the probability someone is 5’8" or taller, assuming that height is normally distributed around 5’8“). We can use the same principle as above to make this calculation. We start by shading in the area under the curve corresponding to 5’8” and taller, like so:</p>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="mathematical-notation-probability-distributions.html#cb180-1" aria-hidden="true" tabindex="-1"></a><span class="do">## We will now plot the normally distributed data as a line (type = &quot;l&quot;)</span></span>
<span id="cb180-2"><a href="mathematical-notation-probability-distributions.html#cb180-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,y, <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;Height in Inches&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Density&quot;</span>)</span>
<span id="cb180-3"><a href="mathematical-notation-probability-distributions.html#cb180-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb180-4"><a href="mathematical-notation-probability-distributions.html#cb180-4" aria-hidden="true" tabindex="-1"></a><span class="do">## we want all values of x and y where x is greater than 68</span></span>
<span id="cb180-5"><a href="mathematical-notation-probability-distributions.html#cb180-5" aria-hidden="true" tabindex="-1"></a><span class="do">## The following three lines of code do this</span></span>
<span id="cb180-6"><a href="mathematical-notation-probability-distributions.html#cb180-6" aria-hidden="true" tabindex="-1"></a>poly_x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">68</span>,x[x<span class="sc">&gt;=</span><span class="dv">68</span>])</span>
<span id="cb180-7"><a href="mathematical-notation-probability-distributions.html#cb180-7" aria-hidden="true" tabindex="-1"></a>index_val <span class="ot">&lt;-</span> <span class="fu">which</span>(x <span class="sc">==</span> <span class="dv">68</span>)</span>
<span id="cb180-8"><a href="mathematical-notation-probability-distributions.html#cb180-8" aria-hidden="true" tabindex="-1"></a>poly_y <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>,y[index_val<span class="sc">:</span><span class="fu">length</span>(y)])</span>
<span id="cb180-9"><a href="mathematical-notation-probability-distributions.html#cb180-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb180-10"><a href="mathematical-notation-probability-distributions.html#cb180-10" aria-hidden="true" tabindex="-1"></a><span class="do">## Then we plot it</span></span>
<span id="cb180-11"><a href="mathematical-notation-probability-distributions.html#cb180-11" aria-hidden="true" tabindex="-1"></a><span class="fu">polygon</span>(poly_x,poly_y,<span class="at">col =</span> <span class="st">&quot;slateblue1&quot;</span>)</span></code></pre></div>
<p><img src="Intro-to-Applied-Stats-with-R_files/figure-html/unnamed-chunk-78-1.png" width="672" /></p>
<p>Intuitively, since the normal distribution is symmetrical, it appears that there is a 50% chance that the height of the next person to walk in will be average (5’8") or greater. We can check with the auc function:</p>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb181-1"><a href="mathematical-notation-probability-distributions.html#cb181-1" aria-hidden="true" tabindex="-1"></a><span class="do">## First we take the integral of our curve using the AUC function in the MESS library</span></span>
<span id="cb181-2"><a href="mathematical-notation-probability-distributions.html#cb181-2" aria-hidden="true" tabindex="-1"></a><span class="do">## AUC stands for &quot;Area Under the Curve&quot;</span></span>
<span id="cb181-3"><a href="mathematical-notation-probability-distributions.html#cb181-3" aria-hidden="true" tabindex="-1"></a>AUC <span class="ot">&lt;-</span> MESS<span class="sc">::</span><span class="fu">auc</span>(poly_x,poly_y)</span></code></pre></div>
<pre><code>## Warning in regularize.values(x, y, ties, missing(ties)): collapsing to unique
## &#39;x&#39; values</code></pre>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb183-1"><a href="mathematical-notation-probability-distributions.html#cb183-1" aria-hidden="true" tabindex="-1"></a><span class="do">## We will round the result to two decimal for ease of reading</span></span>
<span id="cb183-2"><a href="mathematical-notation-probability-distributions.html#cb183-2" aria-hidden="true" tabindex="-1"></a><span class="do">## Taking integrals of lines is an imperfect art so R doesn&#39;t get exactly 1</span></span>
<span id="cb183-3"><a href="mathematical-notation-probability-distributions.html#cb183-3" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(AUC,<span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 0.5</code></pre>
<p>Perfect! Now let’s do one more…at the beginning of the example, I asked how likely it is that someone 6’6" or taller walks through the door next (or <span class="math inline">\(P(X &gt;= 6&#39;6&quot;\)</span>)). We can do that like so:</p>
<div class="sourceCode" id="cb185"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb185-1"><a href="mathematical-notation-probability-distributions.html#cb185-1" aria-hidden="true" tabindex="-1"></a><span class="do">## We will now plot the normally distributed data as a line (type = &quot;l&quot;)</span></span>
<span id="cb185-2"><a href="mathematical-notation-probability-distributions.html#cb185-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,y, <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;Height in Inches&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Density&quot;</span>)</span>
<span id="cb185-3"><a href="mathematical-notation-probability-distributions.html#cb185-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb185-4"><a href="mathematical-notation-probability-distributions.html#cb185-4" aria-hidden="true" tabindex="-1"></a><span class="do">## we want all values of x and y where x is greater than 68</span></span>
<span id="cb185-5"><a href="mathematical-notation-probability-distributions.html#cb185-5" aria-hidden="true" tabindex="-1"></a><span class="do">## The following three lines of code do this</span></span>
<span id="cb185-6"><a href="mathematical-notation-probability-distributions.html#cb185-6" aria-hidden="true" tabindex="-1"></a>poly_x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">78</span>,x[x<span class="sc">&gt;=</span><span class="dv">78</span>])</span>
<span id="cb185-7"><a href="mathematical-notation-probability-distributions.html#cb185-7" aria-hidden="true" tabindex="-1"></a>index_val <span class="ot">&lt;-</span> <span class="fu">which</span>(x <span class="sc">==</span> <span class="dv">78</span>)</span>
<span id="cb185-8"><a href="mathematical-notation-probability-distributions.html#cb185-8" aria-hidden="true" tabindex="-1"></a>poly_y <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>,y[index_val<span class="sc">:</span><span class="fu">length</span>(y)])</span>
<span id="cb185-9"><a href="mathematical-notation-probability-distributions.html#cb185-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb185-10"><a href="mathematical-notation-probability-distributions.html#cb185-10" aria-hidden="true" tabindex="-1"></a><span class="do">## Then we plot it</span></span>
<span id="cb185-11"><a href="mathematical-notation-probability-distributions.html#cb185-11" aria-hidden="true" tabindex="-1"></a><span class="fu">polygon</span>(poly_x,poly_y,<span class="at">col =</span> <span class="st">&quot;slateblue1&quot;</span>)</span></code></pre></div>
<p><img src="Intro-to-Applied-Stats-with-R_files/figure-html/unnamed-chunk-80-1.png" width="672" /></p>
<div class="sourceCode" id="cb186"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb186-1"><a href="mathematical-notation-probability-distributions.html#cb186-1" aria-hidden="true" tabindex="-1"></a><span class="do">## First we take the integral of our curve using the AUC function in the MESS library</span></span>
<span id="cb186-2"><a href="mathematical-notation-probability-distributions.html#cb186-2" aria-hidden="true" tabindex="-1"></a><span class="do">## AUC stands for &quot;Area Under the Curve&quot;</span></span>
<span id="cb186-3"><a href="mathematical-notation-probability-distributions.html#cb186-3" aria-hidden="true" tabindex="-1"></a>AUC <span class="ot">&lt;-</span> MESS<span class="sc">::</span><span class="fu">auc</span>(poly_x,poly_y)</span></code></pre></div>
<pre><code>## Warning in regularize.values(x, y, ties, missing(ties)): collapsing to unique
## &#39;x&#39; values</code></pre>
<div class="sourceCode" id="cb188"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb188-1"><a href="mathematical-notation-probability-distributions.html#cb188-1" aria-hidden="true" tabindex="-1"></a><span class="do">## We will round the result to two decimal for ease of reading</span></span>
<span id="cb188-2"><a href="mathematical-notation-probability-distributions.html#cb188-2" aria-hidden="true" tabindex="-1"></a><span class="do">## Taking integrals of lines is an imperfect art so R doesn&#39;t get exactly 1</span></span>
<span id="cb188-3"><a href="mathematical-notation-probability-distributions.html#cb188-3" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(AUC,<span class="dv">4</span>)</span></code></pre></div>
<pre><code>## [1] 0.0061</code></pre>
<p>As we can see, we think it is quite unlikely that the next person to walk through the door will be 6’6" or taller! In fact, rounding to 4 decimals, our distribution is suggesting to us that there is only a 0.61% chance that the next person to walk in will be 6’6" or taller. I would say that matches up pretty well with how often I bump into folks that are that tall!</p>
</div>
<div id="cannot-prove-that-a-variable-follows-a-distribution" class="section level4" number="5.2.1.4">
<h4><span class="header-section-number">5.2.1.4</span> Cannot Prove That A Variable Follows a Distribution</h4>
<p>So, this is one of the tricky parts of statistics. We cannot prove that a variable <span class="math inline">\(X\)</span> truly follows a given distribution. Generally, we assume that it does until evidence is presented to us that we should not. For example, we have displayed above why it makes sense to assume that height is normally distributed. The way we understand how height is distributed throughout the human population matches up with the structure of the normal distribution quite well. However, we cannot truly prove that height is normally distributed - we can only assume that it is. Now, if 100 people walked in the door and half were less than 5’0" tall and half were over 7’0", I might be a lot less confident that height follows a normal distribution. In other words, we can assume that a variable follows a given distribution and then we can look at data to reflect on this assumption. This is a central activity in undertaking inferential statistics.</p>
</div>
<div id="formally-defining-the-normal-distribution" class="section level4" number="5.2.1.5">
<h4><span class="header-section-number">5.2.1.5</span> Formally Defining the Normal Distribution</h4>
<p>This has been a rather descriptive introduction to the normal distribution. Given how important it is, lets go over how we define it and what its properties are. Remember, our job as statisticians is to identify the signal over the noise. Distributions provide us an ability to rigorously navigate the ratio between the two. There are two parameters which define a normal curve: the mean value (denoted <span class="math inline">\(\mu\)</span>, the Greek letter “mew”) and the standard deviation (denoted <span class="math inline">\(\sigma\)</span>, the Greek letter sigma). We can think of the mean as our signal and the standard deviation as a measure of how noisy the data is. The larger the standard deviation, the wider our normal curve is (i.e., the more spread out from the mean value we will expect values to be observed). We can visualize this by plotting multiple normal curves with different standard deviations:</p>
<div class="sourceCode" id="cb190"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb190-1"><a href="mathematical-notation-probability-distributions.html#cb190-1" aria-hidden="true" tabindex="-1"></a>y1 <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(x, <span class="at">mean =</span> <span class="dv">68</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb190-2"><a href="mathematical-notation-probability-distributions.html#cb190-2" aria-hidden="true" tabindex="-1"></a>y3 <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(x, <span class="at">mean =</span> <span class="dv">68</span>, <span class="at">sd =</span> <span class="dv">3</span>)</span>
<span id="cb190-3"><a href="mathematical-notation-probability-distributions.html#cb190-3" aria-hidden="true" tabindex="-1"></a>y6 <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(x, <span class="at">mean =</span> <span class="dv">68</span>, <span class="at">sd =</span> <span class="dv">6</span>)</span>
<span id="cb190-4"><a href="mathematical-notation-probability-distributions.html#cb190-4" aria-hidden="true" tabindex="-1"></a>y10 <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(x, <span class="at">mean =</span> <span class="dv">68</span>, <span class="at">sd =</span> <span class="dv">10</span>)</span>
<span id="cb190-5"><a href="mathematical-notation-probability-distributions.html#cb190-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb190-6"><a href="mathematical-notation-probability-distributions.html#cb190-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,y1,<span class="at">type=</span><span class="st">&quot;l&quot;</span>,<span class="at">xlab =</span> <span class="st">&quot;X&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Density&quot;</span>)</span>
<span id="cb190-7"><a href="mathematical-notation-probability-distributions.html#cb190-7" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x,y3, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>)</span>
<span id="cb190-8"><a href="mathematical-notation-probability-distributions.html#cb190-8" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x,y6, <span class="at">col =</span> <span class="st">&quot;green&quot;</span>)</span>
<span id="cb190-9"><a href="mathematical-notation-probability-distributions.html#cb190-9" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x,y10, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="Intro-to-Applied-Stats-with-R_files/figure-html/unnamed-chunk-81-1.png" width="672" /></p>
<p>All of these curves are normal distributions with the same mean. They just have different standard deviations. We can understand that a distribution with a larger standard deviation is anticipated to represent “noisier” data than that with a smaller standard deviation. This is because, the larger the standard deviation, the more likley it is that we will observe values farther and farther away from the mean value.</p>
<p>As we discussed in our sample, when we assume a variable is normally distributed, we understand that most of the values we will observe will fall close to the mean value. More extreme observations are understood the be rarer. We can quantify this more specifically - if we assume a variable is normally distributed, then we may understand that just over 2/3 (or around 68.2%) of all observations are expected to fall within 1 standard deviation of the mean. Further, that 95% of all observations will fall within 2 standard deviations of the mean. This can be depicted like so:</p>
<p><img src="Images/img_normal_distribution.svg" /></p>
<p>In our example from before with height, we had defined a normal distribution with a mean height of 5’8" and a standard deviation of 4“. By definition, we would anticipate then that there is a 68.2% probability that the next person to walk through the door will be within 4 inches (1 standard deviation) of 5’8” (or, 5’4" through 6’0“) and that there is a 95% probability that the next person will be within 8 inches (2 standard deviations) of 5’8” (or 5’0" through 6’4"). We can confirm this by looking at the area under the curve again:</p>
<div class="sourceCode" id="cb191"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb191-1"><a href="mathematical-notation-probability-distributions.html#cb191-1" aria-hidden="true" tabindex="-1"></a><span class="do">## We will now plot the normally distributed data as a line (type = &quot;l&quot;)</span></span>
<span id="cb191-2"><a href="mathematical-notation-probability-distributions.html#cb191-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,y, <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;Height in Inches&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Density&quot;</span>)</span>
<span id="cb191-3"><a href="mathematical-notation-probability-distributions.html#cb191-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb191-4"><a href="mathematical-notation-probability-distributions.html#cb191-4" aria-hidden="true" tabindex="-1"></a><span class="do">## we want all values of x and y where x is greater than 68</span></span>
<span id="cb191-5"><a href="mathematical-notation-probability-distributions.html#cb191-5" aria-hidden="true" tabindex="-1"></a><span class="do">## The following three lines of code do this</span></span>
<span id="cb191-6"><a href="mathematical-notation-probability-distributions.html#cb191-6" aria-hidden="true" tabindex="-1"></a>poly_x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">64</span>,x[x<span class="sc">&gt;=</span><span class="dv">64</span> <span class="sc">&amp;</span> x<span class="sc">&lt;=</span><span class="dv">72</span>],<span class="dv">72</span>)</span>
<span id="cb191-7"><a href="mathematical-notation-probability-distributions.html#cb191-7" aria-hidden="true" tabindex="-1"></a>index_low <span class="ot">&lt;-</span> <span class="fu">which</span>(x <span class="sc">==</span> <span class="dv">64</span>)</span>
<span id="cb191-8"><a href="mathematical-notation-probability-distributions.html#cb191-8" aria-hidden="true" tabindex="-1"></a>index_high <span class="ot">&lt;-</span> <span class="fu">which</span>(x <span class="sc">==</span> <span class="dv">72</span>)</span>
<span id="cb191-9"><a href="mathematical-notation-probability-distributions.html#cb191-9" aria-hidden="true" tabindex="-1"></a>poly_y <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>,y[index_low<span class="sc">:</span>index_high],<span class="dv">0</span>)</span>
<span id="cb191-10"><a href="mathematical-notation-probability-distributions.html#cb191-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb191-11"><a href="mathematical-notation-probability-distributions.html#cb191-11" aria-hidden="true" tabindex="-1"></a><span class="do">## Then we plot it</span></span>
<span id="cb191-12"><a href="mathematical-notation-probability-distributions.html#cb191-12" aria-hidden="true" tabindex="-1"></a><span class="fu">polygon</span>(poly_x,poly_y,<span class="at">col =</span> <span class="st">&quot;slateblue1&quot;</span>)</span></code></pre></div>
<p><img src="Intro-to-Applied-Stats-with-R_files/figure-html/unnamed-chunk-82-1.png" width="672" /></p>
<div class="sourceCode" id="cb192"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb192-1"><a href="mathematical-notation-probability-distributions.html#cb192-1" aria-hidden="true" tabindex="-1"></a><span class="do">## First we take the integral of our curve using the AUC function in the MESS library</span></span>
<span id="cb192-2"><a href="mathematical-notation-probability-distributions.html#cb192-2" aria-hidden="true" tabindex="-1"></a><span class="do">## AUC stands for &quot;Area Under the Curve&quot;</span></span>
<span id="cb192-3"><a href="mathematical-notation-probability-distributions.html#cb192-3" aria-hidden="true" tabindex="-1"></a>AUC <span class="ot">&lt;-</span> MESS<span class="sc">::</span><span class="fu">auc</span>(poly_x,poly_y)</span></code></pre></div>
<pre><code>## Warning in regularize.values(x, y, ties, missing(ties)): collapsing to unique
## &#39;x&#39; values</code></pre>
<div class="sourceCode" id="cb194"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb194-1"><a href="mathematical-notation-probability-distributions.html#cb194-1" aria-hidden="true" tabindex="-1"></a><span class="do">## We will round the result to two decimal for ease of reading</span></span>
<span id="cb194-2"><a href="mathematical-notation-probability-distributions.html#cb194-2" aria-hidden="true" tabindex="-1"></a><span class="do">## Taking integrals of lines is an imperfect art so R doesn&#39;t get exactly 1</span></span>
<span id="cb194-3"><a href="mathematical-notation-probability-distributions.html#cb194-3" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(AUC,<span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 0.68</code></pre>
<p>Here, we have filled in the area within 1 standard deviation of the mean and we calculated that this area under the curve sums to 0.68, corresponding to a 68% probability of observing a value within this range! We can do the same for within 2 standard deviations:</p>
<div class="sourceCode" id="cb196"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb196-1"><a href="mathematical-notation-probability-distributions.html#cb196-1" aria-hidden="true" tabindex="-1"></a><span class="do">## We will now plot the normally distributed data as a line (type = &quot;l&quot;)</span></span>
<span id="cb196-2"><a href="mathematical-notation-probability-distributions.html#cb196-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,y, <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;Height in Inches&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Density&quot;</span>)</span>
<span id="cb196-3"><a href="mathematical-notation-probability-distributions.html#cb196-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb196-4"><a href="mathematical-notation-probability-distributions.html#cb196-4" aria-hidden="true" tabindex="-1"></a><span class="do">## we want all values of x and y where x is greater than 68</span></span>
<span id="cb196-5"><a href="mathematical-notation-probability-distributions.html#cb196-5" aria-hidden="true" tabindex="-1"></a><span class="do">## The following three lines of code do this</span></span>
<span id="cb196-6"><a href="mathematical-notation-probability-distributions.html#cb196-6" aria-hidden="true" tabindex="-1"></a>poly_x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">60</span>,x[x<span class="sc">&gt;=</span><span class="dv">60</span> <span class="sc">&amp;</span> x<span class="sc">&lt;=</span><span class="dv">76</span>],<span class="dv">76</span>)</span>
<span id="cb196-7"><a href="mathematical-notation-probability-distributions.html#cb196-7" aria-hidden="true" tabindex="-1"></a>index_low <span class="ot">&lt;-</span> <span class="fu">which</span>(x <span class="sc">==</span> <span class="dv">60</span>)</span>
<span id="cb196-8"><a href="mathematical-notation-probability-distributions.html#cb196-8" aria-hidden="true" tabindex="-1"></a>index_high <span class="ot">&lt;-</span> <span class="fu">which</span>(x <span class="sc">==</span> <span class="dv">76</span>)</span>
<span id="cb196-9"><a href="mathematical-notation-probability-distributions.html#cb196-9" aria-hidden="true" tabindex="-1"></a>poly_y <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>,y[index_low<span class="sc">:</span>index_high],<span class="dv">0</span>)</span>
<span id="cb196-10"><a href="mathematical-notation-probability-distributions.html#cb196-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb196-11"><a href="mathematical-notation-probability-distributions.html#cb196-11" aria-hidden="true" tabindex="-1"></a><span class="do">## Then we plot it</span></span>
<span id="cb196-12"><a href="mathematical-notation-probability-distributions.html#cb196-12" aria-hidden="true" tabindex="-1"></a><span class="fu">polygon</span>(poly_x,poly_y,<span class="at">col =</span> <span class="st">&quot;slateblue1&quot;</span>)</span></code></pre></div>
<p><img src="Intro-to-Applied-Stats-with-R_files/figure-html/unnamed-chunk-83-1.png" width="672" /></p>
<div class="sourceCode" id="cb197"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb197-1"><a href="mathematical-notation-probability-distributions.html#cb197-1" aria-hidden="true" tabindex="-1"></a><span class="do">## First we take the integral of our curve using the AUC function in the MESS library</span></span>
<span id="cb197-2"><a href="mathematical-notation-probability-distributions.html#cb197-2" aria-hidden="true" tabindex="-1"></a><span class="do">## AUC stands for &quot;Area Under the Curve&quot;</span></span>
<span id="cb197-3"><a href="mathematical-notation-probability-distributions.html#cb197-3" aria-hidden="true" tabindex="-1"></a>AUC <span class="ot">&lt;-</span> MESS<span class="sc">::</span><span class="fu">auc</span>(poly_x,poly_y)</span></code></pre></div>
<pre><code>## Warning in regularize.values(x, y, ties, missing(ties)): collapsing to unique
## &#39;x&#39; values</code></pre>
<div class="sourceCode" id="cb199"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb199-1"><a href="mathematical-notation-probability-distributions.html#cb199-1" aria-hidden="true" tabindex="-1"></a><span class="do">## We will round the result to two decimal for ease of reading</span></span>
<span id="cb199-2"><a href="mathematical-notation-probability-distributions.html#cb199-2" aria-hidden="true" tabindex="-1"></a><span class="do">## Taking integrals of lines is an imperfect art so R doesn&#39;t get exactly 1</span></span>
<span id="cb199-3"><a href="mathematical-notation-probability-distributions.html#cb199-3" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(AUC,<span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 0.95</code></pre>
<p>Voila! We can see that 95% of observations fall between 2 standard deviations of the mean! You might be thinking that 95% (or 5%) is an important threshold in the statistics you’ve read or done before - we will get into that more in the next chapter!</p>
</div>
<div id="the-standard-normal-distribution" class="section level4" number="5.2.1.6">
<h4><span class="header-section-number">5.2.1.6</span> The Standard Normal Distribution</h4>
<p>One of the most important distributions is the <strong>standard normal distribution</strong>, sometimes also called the <span class="math inline">\(z\)</span>-distribution. It is a normal distribution whose mean value is 0 and whose standard deviation is 1. We can plot it like so:</p>
<div class="sourceCode" id="cb201"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb201-1"><a href="mathematical-notation-probability-distributions.html#cb201-1" aria-hidden="true" tabindex="-1"></a>x<span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">5</span>,<span class="dv">5</span>,<span class="at">by=</span>.<span class="dv">1</span>)</span>
<span id="cb201-2"><a href="mathematical-notation-probability-distributions.html#cb201-2" aria-hidden="true" tabindex="-1"></a>y<span class="ot">&lt;-</span> <span class="fu">dnorm</span>(x,<span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb201-3"><a href="mathematical-notation-probability-distributions.html#cb201-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-4"><a href="mathematical-notation-probability-distributions.html#cb201-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,y,<span class="at">type=</span><span class="st">&quot;l&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;Density&quot;</span>)</span></code></pre></div>
<p><img src="Intro-to-Applied-Stats-with-R_files/figure-html/unnamed-chunk-84-1.png" width="672" /></p>
<p>You can actually take any value from any normal distribution and standardize it so that it maps onto the z-distribution! This is really useful because it allows us to standardize many of our statistical tests. Standardization is simply the process of dividing the observed signal by the observed noise. Standardization was REALLY important before computers came along. I have been running the auc() function to calculate the area under the curve, but before computers this was actually an incredibly complicated task! Standardzing a curve means that instead of dealing with an infinite possible number of curves, we can just think about one. Old statistics books had tables you could use to check the area under the curve given a specific value on the <span class="math inline">\(z\)</span>-distribution, because calculating the area under the curve is too challenging by hand.</p>
<p>A value that is standardized to the <span class="math inline">\(z\)</span>-distribution is called a <span class="math inline">\(z\)</span>-score. A <span class="math inline">\(z\)</span>-score is calculated by the following formula: <span class="math inline">\(z = \frac{x - \mu}{\sigma}\)</span>, where <span class="math inline">\(x\)</span> is a value observed from a normally distributed variable. In this case, the signal is the difference between the observed value <span class="math inline">\(x\)</span> and the mean value <span class="math inline">\(\mu\)</span> and the noise is the standard deviation <span class="math inline">\(\sigma\)</span>. For example, let us say that someone walked into the room and their height was 70 inches. Well, we know that the mean height <span class="math inline">\(\mu = 68\)</span> and that the standard deviation <span class="math inline">\(\sigma = 4\)</span>. Therefore, the <span class="math inline">\(z\)</span>-score is <span class="math inline">\(\frac{70 - 68}{4} = \frac{2}{4} = 0.5\)</span>.</p>
<p>While, most of the time standardization is going to happen behind the scenes, it is important to reflect on how standardization doesn’t change the expected results - it is just a way of making the data easier to work with. Our process indicates to us that the value of 70 in a normal distribution with mean <span class="math inline">\(\mu = 68\)</span> and standard deviation <span class="math inline">\(\sigma = 4\)</span> is equivalent to <span class="math inline">\(z = 0.5\)</span>. This would mean that the probability of someone being 70 inches or taller <span class="math inline">\(P(X &gt;= 70|\mu = 68, \sigma = 4)\)</span> should have equivalent value to <span class="math inline">\(P(z &gt;= 0.5| \mu = 0, \sigma = 1)\)</span>. Let’s check real quick.</p>
<p>First, we can look at <span class="math inline">\(P(X &gt;= 70|\mu = 68, \sigma = 4)\)</span> by shading in the region of the normal curve corresponding to heights greater than or equal to 70 inches and then we can calculate the area under the curve:</p>
<div class="sourceCode" id="cb202"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb202-1"><a href="mathematical-notation-probability-distributions.html#cb202-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">52</span>, <span class="dv">84</span>, <span class="at">by =</span> .<span class="dv">01</span>)</span>
<span id="cb202-2"><a href="mathematical-notation-probability-distributions.html#cb202-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(x, <span class="at">mean =</span> <span class="dv">68</span>, <span class="at">sd =</span> <span class="dv">4</span>)</span>
<span id="cb202-3"><a href="mathematical-notation-probability-distributions.html#cb202-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb202-4"><a href="mathematical-notation-probability-distributions.html#cb202-4" aria-hidden="true" tabindex="-1"></a><span class="do">## We will now plot the normally distributed data as a line (type = &quot;l&quot;)</span></span>
<span id="cb202-5"><a href="mathematical-notation-probability-distributions.html#cb202-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,y, <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;Height in Inches&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Density&quot;</span>)</span>
<span id="cb202-6"><a href="mathematical-notation-probability-distributions.html#cb202-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb202-7"><a href="mathematical-notation-probability-distributions.html#cb202-7" aria-hidden="true" tabindex="-1"></a><span class="do">## we want all values of x and y where x is greater than 68</span></span>
<span id="cb202-8"><a href="mathematical-notation-probability-distributions.html#cb202-8" aria-hidden="true" tabindex="-1"></a><span class="do">## The following three lines of code do this</span></span>
<span id="cb202-9"><a href="mathematical-notation-probability-distributions.html#cb202-9" aria-hidden="true" tabindex="-1"></a>poly_x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">70</span>,x[x<span class="sc">&gt;=</span><span class="dv">70</span>])</span>
<span id="cb202-10"><a href="mathematical-notation-probability-distributions.html#cb202-10" aria-hidden="true" tabindex="-1"></a>index_val <span class="ot">&lt;-</span> <span class="fu">which</span>(x <span class="sc">==</span> <span class="dv">70</span>)</span>
<span id="cb202-11"><a href="mathematical-notation-probability-distributions.html#cb202-11" aria-hidden="true" tabindex="-1"></a>poly_y <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>,y[index_val<span class="sc">:</span><span class="fu">length</span>(y)])</span>
<span id="cb202-12"><a href="mathematical-notation-probability-distributions.html#cb202-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb202-13"><a href="mathematical-notation-probability-distributions.html#cb202-13" aria-hidden="true" tabindex="-1"></a><span class="do">## Then we plot it</span></span>
<span id="cb202-14"><a href="mathematical-notation-probability-distributions.html#cb202-14" aria-hidden="true" tabindex="-1"></a><span class="fu">polygon</span>(poly_x,poly_y,<span class="at">col =</span> <span class="st">&quot;slateblue1&quot;</span>)</span></code></pre></div>
<p><img src="Intro-to-Applied-Stats-with-R_files/figure-html/unnamed-chunk-85-1.png" width="672" /></p>
<div class="sourceCode" id="cb203"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb203-1"><a href="mathematical-notation-probability-distributions.html#cb203-1" aria-hidden="true" tabindex="-1"></a>AUC <span class="ot">&lt;-</span> MESS<span class="sc">::</span><span class="fu">auc</span>(poly_x,poly_y)</span></code></pre></div>
<pre><code>## Warning in regularize.values(x, y, ties, missing(ties)): collapsing to unique
## &#39;x&#39; values</code></pre>
<div class="sourceCode" id="cb205"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb205-1"><a href="mathematical-notation-probability-distributions.html#cb205-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(AUC,<span class="dv">3</span>)</span></code></pre></div>
<pre><code>## [1] 0.308</code></pre>
<p>We get a value of 0.308. We can do the same process to check the value of <span class="math inline">\(P(z &gt;= 0.5| \mu = 0, \sigma = 1)\)</span>. We will plot the <span class="math inline">\(z\)</span>-distribution and shade in all values greater than or equal to 0.5 and then take the area under the curve:</p>
<div class="sourceCode" id="cb207"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb207-1"><a href="mathematical-notation-probability-distributions.html#cb207-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="at">by =</span> .<span class="dv">01</span>)</span>
<span id="cb207-2"><a href="mathematical-notation-probability-distributions.html#cb207-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(x, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb207-3"><a href="mathematical-notation-probability-distributions.html#cb207-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb207-4"><a href="mathematical-notation-probability-distributions.html#cb207-4" aria-hidden="true" tabindex="-1"></a><span class="do">## We will now plot the normally distributed data as a line (type = &quot;l&quot;)</span></span>
<span id="cb207-5"><a href="mathematical-notation-probability-distributions.html#cb207-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,y, <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;z&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Density&quot;</span>)</span>
<span id="cb207-6"><a href="mathematical-notation-probability-distributions.html#cb207-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb207-7"><a href="mathematical-notation-probability-distributions.html#cb207-7" aria-hidden="true" tabindex="-1"></a><span class="do">## we want all values of x and y where x is greater than 68</span></span>
<span id="cb207-8"><a href="mathematical-notation-probability-distributions.html#cb207-8" aria-hidden="true" tabindex="-1"></a><span class="do">## The following three lines of code do this</span></span>
<span id="cb207-9"><a href="mathematical-notation-probability-distributions.html#cb207-9" aria-hidden="true" tabindex="-1"></a>poly_x <span class="ot">&lt;-</span> <span class="fu">c</span>(.<span class="dv">5</span>,x[x<span class="sc">&gt;=</span>.<span class="dv">5</span>])</span>
<span id="cb207-10"><a href="mathematical-notation-probability-distributions.html#cb207-10" aria-hidden="true" tabindex="-1"></a>index_val <span class="ot">&lt;-</span> <span class="fu">which</span>(x <span class="sc">==</span> .<span class="dv">5</span>)</span>
<span id="cb207-11"><a href="mathematical-notation-probability-distributions.html#cb207-11" aria-hidden="true" tabindex="-1"></a>poly_y <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>,y[index_val<span class="sc">:</span><span class="fu">length</span>(y)])</span>
<span id="cb207-12"><a href="mathematical-notation-probability-distributions.html#cb207-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb207-13"><a href="mathematical-notation-probability-distributions.html#cb207-13" aria-hidden="true" tabindex="-1"></a><span class="do">## Then we plot it</span></span>
<span id="cb207-14"><a href="mathematical-notation-probability-distributions.html#cb207-14" aria-hidden="true" tabindex="-1"></a><span class="fu">polygon</span>(poly_x,poly_y,<span class="at">col =</span> <span class="st">&quot;slateblue1&quot;</span>)</span></code></pre></div>
<p><img src="Intro-to-Applied-Stats-with-R_files/figure-html/unnamed-chunk-86-1.png" width="672" /></p>
<div class="sourceCode" id="cb208"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb208-1"><a href="mathematical-notation-probability-distributions.html#cb208-1" aria-hidden="true" tabindex="-1"></a>AUC <span class="ot">&lt;-</span> MESS<span class="sc">::</span><span class="fu">auc</span>(poly_x,poly_y)</span></code></pre></div>
<pre><code>## Warning in regularize.values(x, y, ties, missing(ties)): collapsing to unique
## &#39;x&#39; values</code></pre>
<div class="sourceCode" id="cb210"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb210-1"><a href="mathematical-notation-probability-distributions.html#cb210-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(AUC,<span class="dv">3</span>)</span></code></pre></div>
<pre><code>## [1] 0.308</code></pre>
<p>As we can see, we get the same exact value! I know that this process of standardizing values may seem a bit odd to do, but it is the foundation of the first inferential technique we will learn about in a few chapters - the <span class="math inline">\(t\)</span>-test. In fact, when we get there, we will actually see that a <span class="math inline">\(t\)</span>-test is actually just a slightly variation of standardizing a normally distributed variable!</p>
</div>
<div id="approximating-a-normal-distribution-from-sample-data" class="section level4" number="5.2.1.7">
<h4><span class="header-section-number">5.2.1.7</span> Approximating a Normal Distribution From Sample Data</h4>
<p>We have covered a whole lot of information in this chapter! The last thing I want to discuss is how we approximate a normal distribution from available data. This is important because usually we do not know what the actual mean and standard deviation of a variable are.</p>
<p>So, let’s say I sat at my desk all day and I counted that <span class="math inline">\(n\)</span> people walked through the door. I wrote down the height of every single person who came in, like so <span class="math inline">\(\{x_1,x_2,x_3,\cdots,x_n\}\)</span>, where <span class="math inline">\(x_i\)</span> represents the height of the <span class="math inline">\(i\)</span>th person to walk through the door.</p>
<p>In order to approximate the theoretical normal distribution we assume to describe height, we must attempt to estimate the mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span> of the height of each person.</p>
<p>It can be helpful to use <span class="math inline">\(\Sigma\)</span> (sigma) notation to make these calculations. <span class="math inline">\(\Sigma\)</span> is used in mathematics to say, “take the sum of” or “add together.” So, if I were to write:</p>
<p><span class="math display">\[\sum_{i = 1}^{n}{x_i}\]</span></p>
<p>, what I am saying is, take the sum of every observation <span class="math inline">\(x_i\)</span>. The <span class="math inline">\(i = 1\)</span> is saying that you should start with <span class="math inline">\(x_1\)</span> and then keep adding the values together until you get to the value at the top, which is <span class="math inline">\(n\)</span> and corresponds to <span class="math inline">\(x_n\)</span>.</p>
<p>The mean value of a sampled variable with <span class="math inline">\(n\)</span> observations is the sum of all the observations divided by the number of observations, <span class="math inline">\(n\)</span>. Or, this can be written as:</p>
<p><span class="math display">\[\bar{x} = \frac{\sum_{i = 1}^{n}{x_i}}{n}\]</span>
We denote this mean with <span class="math inline">\(\bar{x}\)</span> instead of <span class="math inline">\(\mu\)</span> because we have calculated this mean from the sample, not the entire population. We want to make this distinction because there are many applications where we will compare the sample mean <span class="math inline">\(\bar{x}\)</span> to an assumed population mean <span class="math inline">\(\mu\)</span>.</p>
<p>Next, we need to generate an estimation for the standard deviation <span class="math inline">\(\sigma\)</span>. We will use the symbol <span class="math inline">\(s\)</span> to denote the standard deviation when it is calculated from a sample. Our goal in measuring the standard deviation is to attempt to capture how far, on average, each observation <span class="math inline">\(x_i\)</span> is from the mean value <span class="math inline">\(\bar{x}\)</span>. The further observations are from the mean value, the larger the standard deviation is.</p>
<p>Ideally, then we would just take the average of the distance from all the observed values from the mean, but, unfortunately, this actually always equals 0. For example, let’s say our values of <span class="math inline">\(x_i\)</span> were <span class="math inline">\(\{3,10,19,2,1\}\)</span>. Here the mean value is 7 (i.e., <span class="math inline">\(\frac{3 + 10 + 19 + 2 + 1}{5} = \frac{35}{5} = 7\)</span>). We can take the distance of each observation from the mean <span class="math inline">\(\{3 -7,10-7,19-7,2-7,1-7\} = \{-4,3,12,-5,-6\}\)</span> but the sum of all these distances actually equals 0: <span class="math inline">\((-4) + 3 + 12 + (-5) + (-6) = 0\)</span>.</p>
<p>So, we are forced to do an intermediary step and calculate the variance, which we denote as <span class="math inline">\(s^2\)</span>. For the variance, we square the difference between each value and the mean before we sum them. By squaring the value first, we always end up with a positive number. But, we have also squared the values we actually wanted, hence why we consider standard deviation <span class="math inline">\(s\)</span> the square root of variance <span class="math inline">\(s^2\)</span>.</p>
<p>So, to calculate variance we use the following equation:</p>
<p><span class="math display">\[s^2 = \frac{1}{n-1}\sum_{i=1}^{n}{(x_i - \bar{x})^2}\]</span></p>
<p>We can then get the standard deviation because <span class="math inline">\(s = \sqrt{s^2}\)</span>. All we need to do is take the square root of the variance and we have the standard deviation. At this point we have calculated a sample mean <span class="math inline">\(\bar{x}\)</span> and a standard deviation <span class="math inline">\(s\)</span>, which we can consider estimations of both the population-level values <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>. We can use our values of <span class="math inline">\(\bar{x}\)</span> and <span class="math inline">\(s\)</span> to either generate the normal distribution or to standardize the values of our variable onto the <span class="math inline">\(z\)</span>-distribution!</p>
</div>
</div>
</div>
<div id="conclusion" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> Conclusion</h2>
<p>In this text, we have introduced a new language of probability. We have briefly discussed how statistics is an art of falsification - we assume that something is true, typically by assuming that an outcome follows a specific theoretical distribution and then we try to assess how probable our sample data is given our assumption. If the data we observe seems improbable under our assumption, then we might need to question the validity of our assumption.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="working-with-datasets-in-r.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="scientific-research-questions-and-null-hypothesis-significance-testing-framework.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Intro to Applied Stats with R.pdf", "Intro to Applied Stats with R.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
