<<<<<<< HEAD
[
["index.html", "Predicting Synthetic Opioid Outbreaks Chapter 1 What Is In This Book?", " Predicting Synthetic Opioid Outbreaks Charles Marks 2020-01-15 Chapter 1 What Is In This Book? "],
["dataprep.html", "Chapter 2 Data Preparation 2.1 CDC Wonder Data 2.2 American Community Survey 2.3 Additional Variables 2.4 Defining Outcomes 2.5 Neighboring County Variables (including Gravity) 2.6 Save Dataset", " Chapter 2 Data Preparation Prior to undertaking the analysis, we need to prepare our data. We are looking at annual county-level statistics, so here we will create an observation for each countyXyear for all US counties (n = 3143) and all years between 2010 and 2017. To replicate this code, the data has been made available in the following repository. 2.1 CDC Wonder Data 2.1.1 Upload the Datas We will start this process by using data downloaded from the CDC Wonder database. Wonder allows users to extract annual, county-level overdose numbers overall and for specific drugs (ie heroin, cocaine, synthetic opioids, et al). Here we upload datasets extracted from the CDC Wonder database to create our initial dataset. ## load the data synthetic_opioid_data &lt;- read.table(file = &quot;Data/Synthetic_Opioid_Overdose_By_County_2010-2017.txt&quot;, sep = &#39;\\t&#39;, header = TRUE) heroin_data &lt;- read.table(file = &quot;Data/Heroin_Overdose_By_County_2010-2017.txt&quot;, sep = &#39;\\t&#39;, header = TRUE) cocaine_data &lt;- read.table(file = &quot;Data/Cocaine_Overdose_By_County_2010-2017.txt&quot;, sep = &#39;\\t&#39;, header = TRUE) meth_data &lt;- read.table(file = &quot;Data/Meth_Overdose_By_County_2010-2017.txt&quot;, sep = &#39;\\t&#39;, header = TRUE) ## clean the data a little bit synthetic_opioid_data$County &lt;- as.character(synthetic_opioid_data$County) synthetic_opioid_data$Deaths &lt;- (as.character(synthetic_opioid_data$Deaths)) synthetic_opioid_data$Deaths[synthetic_opioid_data$Deaths == &quot;Suppressed&quot;] &lt;- -99 synthetic_opioid_data$Deaths &lt;- (as.numeric(synthetic_opioid_data$Deaths)) synthetic_opioid_data$Population &lt;- as.numeric(as.character(synthetic_opioid_data$Population)) heroin_data$County &lt;- as.character(heroin_data$County) heroin_data$Deaths &lt;- (as.character(heroin_data$Deaths)) heroin_data$Deaths[heroin_data$Deaths == &quot;Suppressed&quot;] &lt;- -99 heroin_data$Deaths &lt;- (as.numeric(heroin_data$Deaths)) heroin_data$Population &lt;- as.numeric(as.character(heroin_data$Population)) cocaine_data$County &lt;- as.character(cocaine_data$County) cocaine_data$Deaths &lt;- (as.character(cocaine_data$Deaths)) cocaine_data$Deaths[cocaine_data$Deaths == &quot;Suppressed&quot;] &lt;- -99 cocaine_data$Deaths &lt;- (as.numeric(cocaine_data$Deaths)) cocaine_data$Population &lt;- as.numeric(as.character(cocaine_data$Population)) meth_data$County &lt;- as.character(meth_data$County) meth_data$Deaths &lt;- (as.character(meth_data$Deaths)) meth_data$Deaths[meth_data$Deaths == &quot;Suppressed&quot;] &lt;- -99 meth_data$Deaths &lt;- (as.numeric(meth_data$Deaths)) meth_data$Population &lt;- as.numeric(as.character(meth_data$Population)) ## merge into one file data &lt;- synthetic_opioid_data[c(2:4,7:6)] data$heroin_deaths &lt;- NA data$cocaine_deaths &lt;- NA data$meth_deaths &lt;- NA for(county_id in unique(data$County.Code)){ for(year in unique(data$Year)){ data$heroin_deaths[data$County.Code == county_id &amp; data$Year == year] &lt;- heroin_data$Deaths[heroin_data$County.Code == county_id &amp; heroin_data$Year == year] data$cocaine_deaths[data$County.Code == county_id &amp; data$Year == year] &lt;- cocaine_data$Deaths[cocaine_data$County.Code == county_id &amp; cocaine_data$Year == year] data$meth_deaths[data$County.Code == county_id &amp; data$Year == year] &lt;- meth_data$Deaths[meth_data$County.Code == county_id &amp; meth_data$Year == year] } } colnames(data) &lt;- c(&quot;county_name&quot;,&quot;county_code&quot;,&quot;year&quot;,&quot;population&quot;,&quot;synthetic_opioid_deaths&quot;,&quot;heroin_deaths&quot;,&quot;cocaine_deaths&quot;,&quot;meth_deaths&quot;) data &lt;- data[!is.na(data$population),] 2.1.2 Imputing Missing Data The CDC suppresses any value beneath 10 (ie if a county had 6 overdose deaths in a given year, the CDC just reports suppressed) and so we need to find a way to impute this value. The CDC recommends a procedure which we update. Essentially for a given state \\(S\\) in a given year \\(Y\\), we take the number of overdoses \\(O\\) in that year and subtract from it all of the non-suppressed county counts \\(o_i\\). The remaining number of deaths, \\(O - \\sum{o_i}\\) is then distributed to the “Suppressed” counties on a population basis. ## load the state data synthetic_opioid_data &lt;- read.table(file = &quot;Data/Synthetic_Opioid_Overdose_By_State_2010-2017.txt&quot;, sep = &#39;\\t&#39;, header = TRUE) heroin_data &lt;- read.table(file = &quot;Data/Heroin_Overdose_By_State_2010-2017.txt&quot;, sep = &#39;\\t&#39;, header = TRUE) cocaine_data &lt;- read.table(file = &quot;Data/Cocaine_Overdose_By_State_2010-2017.txt&quot;, sep = &#39;\\t&#39;, header = TRUE) meth_data &lt;- read.table(file = &quot;Data/Meth_Overdose_By_State_2010-2017.txt&quot;, sep = &#39;\\t&#39;, header = TRUE) ## clean the data a little bit synthetic_opioid_data$State &lt;- as.character(synthetic_opioid_data$State) synthetic_opioid_data$Deaths &lt;- (as.character(synthetic_opioid_data$Deaths)) synthetic_opioid_data$Deaths[synthetic_opioid_data$Deaths == &quot;Suppressed&quot;] &lt;- -99 synthetic_opioid_data$Deaths &lt;- (as.numeric(synthetic_opioid_data$Deaths)) heroin_data$State &lt;- as.character(heroin_data$State) heroin_data$Deaths &lt;- (as.character(heroin_data$Deaths)) heroin_data$Deaths[heroin_data$Deaths == &quot;Suppressed&quot;] &lt;- -99 heroin_data$Deaths &lt;- (as.numeric(heroin_data$Deaths)) cocaine_data$State &lt;- as.character(cocaine_data$State) cocaine_data$Deaths &lt;- (as.character(cocaine_data$Deaths)) cocaine_data$Deaths[cocaine_data$Deaths == &quot;Suppressed&quot;] &lt;- -99 cocaine_data$Deaths &lt;- (as.numeric(cocaine_data$Deaths)) meth_data$State &lt;- as.character(meth_data$State) meth_data$Deaths &lt;- (as.character(meth_data$Deaths)) meth_data$Deaths[meth_data$Deaths == &quot;Suppressed&quot;] &lt;- -99 meth_data$Deaths &lt;- (as.numeric(meth_data$Deaths)) ## now we need to undertake the imputation procedure for(state_id in unique(synthetic_opioid_data$State.Code)){ for(year in unique(synthetic_opioid_data$Year)){ ## we first want to get the total number of deaths for the state total_synthetic_opioid_deaths &lt;- synthetic_opioid_data$Deaths[synthetic_opioid_data$State.Code == state_id &amp; synthetic_opioid_data$Year == year] total_heroin_deaths &lt;- heroin_data$Deaths[heroin_data$State.Code == state_id &amp; heroin_data$Year == year] total_cocaine_deaths &lt;- cocaine_data$Deaths[cocaine_data$State.Code == state_id &amp; cocaine_data$Year == year] total_meth_deaths &lt;- meth_data$Deaths[meth_data$State.Code == state_id &amp; meth_data$Year == year] ## then we want to subtract the number of deaths recorded ## and extract the counties that were suppressed county_data &lt;- data[data$county_code &gt;= state_id*1000 &amp; data$county_code &lt; (state_id*1000 + 1000) &amp; data$year == year,] synthetic_opioid_counties_suppressed &lt;- c() heroin_counties_suppressed &lt;- c() cocaine_counties_suppressed &lt;- c() meth_counties_suppressed &lt;- c() for(county_id in unique(county_data$county_code)){ ## synthetic opioid so_death &lt;- county_data$synthetic_opioid_deaths[county_data$county_code == county_id] if(so_death == -99){ synthetic_opioid_counties_suppressed &lt;- c(synthetic_opioid_counties_suppressed, county_id) }else{ total_synthetic_opioid_deaths &lt;- total_synthetic_opioid_deaths - so_death } ## heroin h_death &lt;- county_data$heroin_deaths[county_data$county_code == county_id] if(h_death == -99){ heroin_counties_suppressed &lt;- c(heroin_counties_suppressed, county_id) }else{ total_heroin_deaths &lt;- total_heroin_deaths - h_death } ## cocaine c_death &lt;- county_data$cocaine_deaths[county_data$county_code == county_id] if(c_death == -99){ cocaine_counties_suppressed &lt;- c(cocaine_counties_suppressed, county_id) }else{ total_cocaine_deaths &lt;- total_cocaine_deaths - c_death } ## meth m_death &lt;- county_data$meth_deaths[county_data$county_code == county_id] if(m_death == -99){ meth_counties_suppressed &lt;- c(meth_counties_suppressed, county_id) }else{ total_meth_deaths &lt;- total_meth_deaths - m_death } } ## now we get the population rate of deaths for suppressed counties synthetic_opioid_suppressed_pop &lt;- 0 heroin_suppressed_pop &lt;- 0 cocaine_suppressed_pop &lt;- 0 meth_suppressed_pop &lt;- 0 for(county_id in synthetic_opioid_counties_suppressed){ synthetic_opioid_suppressed_pop &lt;- synthetic_opioid_suppressed_pop + county_data$population[county_data$county_code == county_id] } for(county_id in heroin_counties_suppressed){ heroin_suppressed_pop &lt;- heroin_suppressed_pop + county_data$population[county_data$county_code == county_id] } for(county_id in cocaine_counties_suppressed){ cocaine_suppressed_pop &lt;- cocaine_suppressed_pop + county_data$population[county_data$county_code == county_id] } for(county_id in meth_counties_suppressed){ meth_suppressed_pop &lt;- meth_suppressed_pop + county_data$population[county_data$county_code == county_id] } synthetic_opioid_rate &lt;- 0 if(synthetic_opioid_suppressed_pop &gt; 0){ synthetic_opioid_rate &lt;- total_synthetic_opioid_deaths/synthetic_opioid_suppressed_pop } heroin_rate &lt;- 0 if(heroin_suppressed_pop &gt; 0){ heroin_rate &lt;- total_heroin_deaths/heroin_suppressed_pop } cocaine_rate &lt;- 0 if(cocaine_suppressed_pop &gt; 0){ cocaine_rate &lt;- total_cocaine_deaths/cocaine_suppressed_pop } meth_rate &lt;- 0 if(meth_suppressed_pop &gt; 0){ meth_rate &lt;- total_meth_deaths/meth_suppressed_pop } if(synthetic_opioid_rate &lt; 0){ synthetic_opioid_rate &lt;- 0} if(heroin_rate &lt; 0){ heroin_rate &lt;- 0} if(cocaine_rate &lt; 0){ cocaine_rate &lt;- 0} if(meth_rate &lt; 0){ meth_rate &lt;- 0} ## we now want to apply these rates to calculate an imputed value for each suppressed county in the actual data set ## note that we know that the crude number does not exceed 9 and thus we use the min() function to cap the value at 9 for(county_id in unique(county_data$county_code)){ county_pop &lt;- data$population[data$county_code == county_id &amp; data$year == year] if(data$synthetic_opioid_deaths[data$county_code == county_id &amp; data$year == year] == -99){ data$synthetic_opioid_deaths[data$county_code == county_id &amp; data$year == year] &lt;- min(county_pop*synthetic_opioid_rate,9) } if(data$heroin_deaths[data$county_code == county_id &amp; data$year == year] == -99){ data$heroin_deaths[data$county_code == county_id &amp; data$year == year] &lt;- min(county_pop*heroin_rate,9) } if(data$cocaine_deaths[data$county_code == county_id &amp; data$year == year] == -99){ data$cocaine_deaths[data$county_code == county_id &amp; data$year == year] &lt;- min(county_pop*cocaine_rate,9) } if(data$meth_deaths[data$county_code == county_id &amp; data$year == year] == -99){ data$meth_deaths[data$county_code == county_id &amp; data$year == year] &lt;- min(county_pop*meth_rate,9) } } } } 2.1.3 Calculating Crude Rates Now, with the imputed values we are then able to calculate the crude deaths rates of each county (per 100,000 people). This is done by dividing the number of deaths by the size of population and then multiplying this value by 100,000. data$synthetic_opioid_crude_death_rate &lt;- 100000*(data$synthetic_opioid_deaths/data$population) data$heroin_crude_death_rate &lt;- 100000*(data$heroin_deaths/data$population) data$cocaine_crude_death_rate &lt;- 100000*(data$cocaine_deaths/data$population) data$meth_crude_death_rate &lt;- 100000*(data$meth_deaths/data$population) 2.2 American Community Survey We would also like to add some demographic data, which is available from the ACS. This dataset has been created by merging multiple ACS data files, the code for which is contained in the appendix. ACS &lt;- read.csv(&quot;Data/Updated_ACS_data.csv&quot;, header = T) for(i in 1:nrow(ACS)){ for(j in 1:ncol(ACS)){ if(is.na(ACS[i,j])){ ACS[i,j] &lt;- -999 } } } data$unemployment_rate &lt;- NA data$median_household_income &lt;- NA data$mean_household_income &lt;- NA data$proportion_poverty &lt;- NA data$proportion_uninsured &lt;- NA data$proportion_homes_no_vehicle &lt;- NA data$proportion_homeowners_35perc_income &lt;- NA data$proportion_renters_35perc_income &lt;- NA data$proportion_white &lt;- NA data$proportion_black &lt;- NA data$proportion_american_indian_alaska_native &lt;- NA data$proportion_asian &lt;- NA data$proportion_native_hawaiian_pacific_islander &lt;- NA data$proportion_male &lt;- NA data$proportion_high_school_or_greater &lt;- NA data$proportion_bachelors_or_greater &lt;- NA for(i in 1:nrow(data)){ if(data$county_code[i] %in% c(2201,2232,2280)){} ## three Alaskan counties which don&#39;t have data. else{ data$unemployment_rate[i] &lt;- ACS$Unemployment_Rate[ACS$ID == data$county_code[i] &amp; ACS$Year == data$year[i]] data$median_household_income[i] &lt;- ACS$Median_Household_Income[ACS$ID == data$county_code[i] &amp; ACS$Year == data$year[i]] data$mean_household_income[i] &lt;- ACS$Mean_Household_Income[ACS$ID == data$county_code[i] &amp; ACS$Year == data$year[i]] data$proportion_poverty[i] &lt;- ACS$Proportion_Poverty[ACS$ID == data$county_code[i] &amp; ACS$Year == data$year[i]] data$proportion_uninsured[i] &lt;- ACS$Proportion_Uninsured[ACS$ID == data$county_code[i] &amp; ACS$Year == data$year[i]] data$proportion_homes_no_vehicle[i] &lt;- ACS$Proportion_Homes_No_Vehicle[ACS$ID == data$county_code[i] &amp; ACS$Year == data$year[i]] data$proportion_homeowners_35perc_income[i] &lt;- ACS$Proportion_Homeowners_35Perc_Income_on_Home[ACS$ID == data$county_code[i] &amp; ACS$Year == data$year[i]] data$proportion_renters_35perc_income[i] &lt;- ACS$Proportion_Renters_35Perc_Income_on_Rent[ACS$ID == data$county_code[i] &amp; ACS$Year == data$year[i]] data$proportion_white[i] &lt;- ACS$Proportion_White[ACS$ID == data$county_code[i] &amp; ACS$Year == data$year[i]] data$proportion_black[i] &lt;- ACS$Proportion_Black[ACS$ID == data$county_code[i] &amp; ACS$Year == data$year[i]] data$proportion_american_indian_alaska_native[i] &lt;- ACS$Proportion_American_Indian_Alaska_Native[ACS$ID == data$county_code[i] &amp; ACS$Year == data$year[i]] data$proportion_asian[i] &lt;- ACS$Proportion_Asian[ACS$ID == data$county_code[i] &amp; ACS$Year == data$year[i]] data$proportion_native_hawaiian_pacific_islander[i] &lt;- ACS$Proportion_Native_Hawaiian_Pacific_Islander[ACS$ID == data$county_code[i] &amp; ACS$Year == data$year[i]] data$proportion_male[i] &lt;- ACS$Proportion_Male[ACS$ID == data$county_code[i] &amp; ACS$Year == data$year[i]] data$proportion_high_school_or_greater[i] &lt;- ACS$Proportion_High_School_or_Greater[ACS$ID == data$county_code[i] &amp; ACS$Year == data$year[i]] data$proportion_bachelors_or_greater[i] &lt;- ACS$Proportion_Bachelors_Degree_or_Greater[ACS$ID == data$county_code[i] &amp; ACS$Year == data$year[i]] } } for(i in 1:nrow(ACS)){ for(j in 1:ncol(ACS)){ if(ACS[i,j] == -999){ ACS[i,j] &lt;- NA } } } 2.3 Additional Variables 2.3.1 Hepatitis C Mortality (CDC Wonder) We used a very similar approach for this variable as for our specific drug use mortalities, using state level estimates to impute suppressed county numbers. hepatitis_state_data &lt;- read.table(file = &quot;Data/Hepatitis_C_Mortality_By_State.txt&quot;, sep = &#39;\\t&#39;, header = TRUE) hepatitis_county_data &lt;- read.table(file = &quot;Data/Hepatitis_C_Mortality_By_County.txt&quot;, sep = &#39;\\t&#39;, header = TRUE) ## clean the data a little bit hepatitis_state_data$State &lt;- as.character(hepatitis_state_data$State) hepatitis_state_data$Deaths &lt;- (as.character(hepatitis_state_data$Deaths)) hepatitis_state_data$Deaths[hepatitis_state_data$Deaths == &quot;Suppressed&quot;] &lt;- -99 hepatitis_state_data$Deaths &lt;- (as.numeric(hepatitis_state_data$Deaths)) hepatitis_county_data$County &lt;- as.character(hepatitis_county_data$County) hepatitis_county_data$Deaths &lt;- (as.character(hepatitis_county_data$Deaths)) hepatitis_county_data$Deaths[hepatitis_county_data$Deaths == &quot;Suppressed&quot;] &lt;- -99 hepatitis_county_data$Deaths &lt;- (as.numeric(hepatitis_county_data$Deaths)) hepatitis_county_data$Population &lt;- as.numeric(as.character(hepatitis_county_data$Population)) ## now we need to undertake the imputation procedure for(state_id in unique(hepatitis_state_data$State.Code)){ for(year in unique(hepatitis_state_data$Year)){ ## we first want to get the total number of deaths for the state total_hepatitis_deaths &lt;- hepatitis_state_data$Deaths[hepatitis_state_data$State.Code == state_id &amp; hepatitis_state_data$Year == year] ## then we want to subtract the number of deaths recorded ## and extract the counties that were suppressed county_data &lt;- hepatitis_county_data[hepatitis_county_data$County.Code &gt;= state_id*1000 &amp; hepatitis_county_data$County.Code &lt; (state_id*1000 + 1000) &amp; hepatitis_county_data$Year == year,] counties_suppressed &lt;- c() for(county_id in unique(county_data$County.Code)){ death &lt;- county_data$Deaths[county_data$County.Code == county_id] if(is.na(death)){ } else if(death == -99){ counties_suppressed &lt;- c(counties_suppressed, county_id) }else{ total_hepatitis_deaths &lt;- total_hepatitis_deaths - death } } ## now we get the population rate of deaths for suppressed counties suppressed_pop &lt;- 0 for(county_id in counties_suppressed){ suppressed_pop &lt;- suppressed_pop + county_data$Population[county_data$County.Code == county_id] } death_rate &lt;- 0 if(suppressed_pop &gt; 0){ death_rate &lt;- total_hepatitis_deaths/suppressed_pop } if(death_rate &lt; 0){ death_rate &lt;- 0} ## we now want to apply these rates to calculate an imputed value for each suppressed county in the actual data set ## note that we know that the crude number does not exceed 9 and thus we use the min() function to cap the value at 9 for(county_id in unique(county_data$County.Code)){ county_pop &lt;- county_data$Population[county_data$County.Code == county_id] if(is.na(county_data$Deaths[county_data$County.Code == county_id])){ }else if(county_data$Deaths[county_data$County.Code == county_id] == -99){ hepatitis_county_data$Deaths[hepatitis_county_data$County.Code == county_id &amp; hepatitis_county_data$Year == year] &lt;- min(county_pop*death_rate,9) } } } } ## so now we want to merge this data into our final dataset ## note that we need to convert this into an actual rate when we do this data$hep_c_mortality_rate &lt;- NA for(i in 1:nrow(data)){ year &lt;- data$year[i] county &lt;- data$county_code[i] numbers_of_deaths &lt;- hepatitis_county_data$Deaths[hepatitis_county_data$County.Code == county &amp; hepatitis_county_data$Year == year] population &lt;- data$population[i] hepatitis_mortality_rate &lt;- 100000*(numbers_of_deaths/population) data$hep_c_mortality_rate[i] &lt;- hepatitis_mortality_rate } 2.3.2 Urbanicity urbanicity &lt;- read.csv(&quot;Data/Urbanicity.csv&quot;, header = T) data$urbanicity &lt;- NA for(id in unique(data$county_code)){ urban &lt;- urbanicity$X2013.code[urbanicity$ï..FIPS.code == id] data$urbanicity[data$county_code == id] &lt;- urban } 2.3.3 Opioid Prescribing https://www.cdc.gov/drugoverdose/maps/rxrate-maps.html prescribing &lt;- read.csv(&quot;Data/Opioid_Prescribing_per_100.csv&quot;, header = T) prescribing$Rate_per_100 &lt;- as.numeric(as.character(prescribing$Rate_per_100)) data$opioid_prescriptions_per_100 &lt;- NA for(i in 1:nrow(data)){ year &lt;- data$year[i] county &lt;- data$county_code[i] prescriptions &lt;- prescribing$Rate_per_100[prescribing$State.County.FIPS.Code == county &amp; prescribing$Year == year] if(length(prescriptions) &gt; 0){ data$opioid_prescriptions_per_100[i] &lt;- prescriptions } } ### Need to Impute the missing data ### Lets match on state and urbanicity? for(year in 2010:2017){ for(state in 1:56){ counties &lt;- data[data$year == year &amp; data$county_code &gt;= state*1000 &amp; data$county_code &lt; (state + 1)*1000,] for(urbanicity in 1:6){ urb_cnty &lt;- counties[counties$urbanicity == urbanicity,] rate &lt;- mean(urb_cnty$opioid_prescriptions_per_100, na.rm = T) data$opioid_prescriptions_per_100[data$urbanicity == urbanicity &amp; data$county_code %in% urb_cnty$county_code &amp; data$year == year &amp; is.na(data$opioid_prescriptions_per_100)] &lt;- rate } } } 2.3.4 Population Density land_area &lt;- read.csv(&quot;Data/Land_Area.csv&quot;, header = T) data$population_density &lt;- NA for(id in unique(data$county_code)){ if(id %in% c(2201,2232,2280)){} ## three Alaskan counties which don&#39;t have data. else{ la &lt;- land_area$Land_Area[land_area$FIPS == id] subset &lt;- data[data$county_code == id,] for(year in unique(subset$year)){ population &lt;- subset$population[subset$year == year] pop_density &lt;- population/la data$population_density[data$county_code == id &amp; data$year == year] &lt;- pop_density } } } data$log_population_density &lt;- log(data$population_density) 2.3.5 Police Violence police_violence &lt;- read.csv(&quot;Data/annual_police_violence_by_county.csv&quot;, header = T) data$police_violence &lt;- NA for(i in 1:nrow(data)){ year &lt;- data$year[i] fips &lt;- data$county_code[i] if(year == 2010){ killings &lt;- police_violence$deaths_2010[police_violence$county_fips == fips] if(length(killings) &gt; 0 &amp;&amp; killings &gt; 0){ data$police_violence[i] &lt;- T }else if(length(killings) &gt;0 &amp;&amp; killings == 0){ data$police_violence[i] &lt;- F } }else if(year == 2011){ killings &lt;- police_violence$deaths_2011[police_violence$county_fips == fips] if(length(killings) &gt; 0 &amp;&amp; killings &gt; 0){ data$police_violence[i] &lt;- T }else if(length(killings) &gt;0 &amp;&amp; killings == 0){ data$police_violence[i] &lt;- F } }else if(year == 2012){ killings &lt;- police_violence$deaths_2012[police_violence$county_fips == fips] if(length(killings) &gt; 0 &amp;&amp; killings &gt; 0){ data$police_violence[i] &lt;- T }else if(length(killings) &gt;0 &amp;&amp; killings == 0){ data$police_violence[i] &lt;- F } }else if(year == 2013){ killings &lt;- police_violence$deaths_2013[police_violence$county_fips == fips] if(length(killings) &gt; 0 &amp;&amp; killings &gt; 0){ data$police_violence[i] &lt;- T }else if(length(killings) &gt;0 &amp;&amp; killings == 0){ data$police_violence[i] &lt;- F } }else if(year == 2014){ killings &lt;- police_violence$deaths_2014[police_violence$county_fips == fips] if(length(killings) &gt; 0 &amp;&amp; killings &gt; 0){ data$police_violence[i] &lt;- T }else if(length(killings) &gt;0 &amp;&amp; killings == 0){ data$police_violence[i] &lt;- F } }else if(year == 2015){ killings &lt;- police_violence$deaths_2015[police_violence$county_fips == fips] if(length(killings) &gt; 0 &amp;&amp; killings &gt; 0){ data$police_violence[i] &lt;- T }else if(length(killings) &gt;0 &amp;&amp; killings == 0){ data$police_violence[i] &lt;- F } }else if(year == 2016){ killings &lt;- police_violence$deaths_2016[police_violence$county_fips == fips] if(length(killings) &gt; 0 &amp;&amp; killings &gt; 0){ data$police_violence[i] &lt;- T }else if(length(killings) &gt;0 &amp;&amp; killings == 0){ data$police_violence[i] &lt;- F } }else if(year == 2017){ killings &lt;- police_violence$deaths_2017[police_violence$county_fips == fips] if(length(killings) &gt; 0 &amp;&amp; killings &gt; 0){ data$police_violence[i] &lt;- T }else if(length(killings) &gt;0 &amp;&amp; killings == 0){ data$police_violence[i] &lt;- F } } } 2.3.6 Road Access &amp; Urgent Care Facilities hospitals &lt;- read.csv(&quot;Data/roads_urgent_care.csv&quot;, header = T) data$road_access &lt;- NA data$urgent_care &lt;- NA for(id in unique(data$county_code)){ road_access &lt;- hospitals$roads_access[hospitals$GEOID == id] urgent_care &lt;- hospitals$urgent_care[hospitals$GEOID == id] if(length(road_access) &gt; 0 &amp;&amp; road_access == &quot;yes&quot;){ road_access &lt;- T } else{ road_access&lt;- F} if(length(urgent_care) &gt; 0 &amp;&amp; urgent_care == &quot;yes&quot;){ urgent_care &lt;- T }else{urgent_care &lt;- F} data$road_access[data$county_code == id] &lt;- road_access data$urgent_care[data$county_code == id] &lt;- urgent_care } 2.4 Defining Outcomes So, we have established the annual data, but, because we are looking at projecting into the future, we need to pair observations with future outcomes. Essentially, we will pair each observation with the synthetic opioid death rates corresponding to one year, two years, and three years into the future. This is of interest because mortality data isn’t typically available in time to make next year predictions. We can use these to show the importance of releasing data swiftly. ## for now we are focusing on synthetic opioids ## we will create two variables, next year and in two years data$next_year_synthetic_opioid_death_rate &lt;- NA data$two_year_out_synthetic_opioid_death_rate &lt;- NA for(fips in unique(data$county_code)){ for(year in 2010:2016){ next_year &lt;- data$synthetic_opioid_crude_death_rate[data$year == year + 1 &amp; data$county_code == fips] if(length(next_year) &gt; 0){ data$next_year_synthetic_opioid_death_rate[data$year == year &amp; data$county_code == fips] &lt;- next_year } if(year &lt; 2016){ second_year &lt;- data$synthetic_opioid_crude_death_rate[data$year == year + 2 &amp; data$county_code == fips] if(length(second_year) &gt; 0){ data$two_year_out_synthetic_opioid_death_rate[data$year == year &amp; data$county_code == fips] &lt;- second_year } } } } 2.5 Neighboring County Variables (including Gravity) Of interest is considering how the presence of overdose in neighboring counties impacts overdose in a given county. A gravity approach is considered appropriate so here we will create gravity metrics for each of the four classes of overdose we have defined in our dataset (synthetic opioids, heroin, meth, cocaine). We multiply the overdose rates of two counties and divide by the distance to get the gravity between two counties. Each county’s gravity metric is the sum of all gravity scores. rm(list=setdiff(ls(), &quot;data&quot;)) distances &lt;- read.csv(&quot;Data/County_Distances.csv&quot;, header = T) data$synthetic_opiod_gravity &lt;- NA data$heroin_gravity &lt;- NA data$cocaine_gravity &lt;- NA data$meth_gravity &lt;- NA for(i in 1:nrow(data)){ print(i) fips &lt;- data$county_code[i] year &lt;- data$year[i] synth_od &lt;- data$synthetic_opioid_crude_death_rate[i] heroin_od &lt;- data$heroin_crude_death_rate[i] cocaine_od &lt;- data$cocaine_crude_death_rate[i] meth_od &lt;- data$meth_crude_death_rate[i] dist &lt;- distances[distances$county1 == fips &amp; distances$mi_to_county &lt; 200,] synth_gravity &lt;- 0 heroin_gravity &lt;- 0 cocaine_gravity &lt;- 0 meth_gravity &lt;- 0 for(j in 1:nrow(dist)){ fips2 &lt;- dist$county2[j] d &lt;- dist$mi_to_county[j] synth_od2 &lt;- data$synthetic_opioid_crude_death_rate[data$county_code == fips2 &amp; data$year == year] heroin_od2 &lt;- data$heroin_crude_death_rate[data$county_code == fips2 &amp; data$year == year] cocaine_od2 &lt;- data$cocaine_crude_death_rate[data$county_code == fips2 &amp; data$year == year] meth_od2 &lt;- data$meth_crude_death_rate[data$county_code == fips2 &amp; data$year == year] if(length(synth_od2) &gt; 0){ synth_gravity &lt;- synth_gravity + ((synth_od*synth_od2)/(d^2)) } if(length(heroin_od2) &gt; 0){ heroin_gravity &lt;- heroin_gravity + ((heroin_od*heroin_od2)/(d^2)) } if(length(cocaine_od2) &gt; 0){ cocaine_gravity &lt;- cocaine_gravity + ((cocaine_od*cocaine_od2)/(d^2)) } if(length(meth_od2) &gt; 0){ meth_gravity &lt;- meth_gravity + ((meth_od*meth_od2)/(d^2)) } } data$synthetic_opiod_gravity[i] &lt;- synth_gravity data$heroin_gravity[i] &lt;- heroin_gravity data$cocaine_gravity[i] &lt;- cocaine_gravity data$meth_gravity[i] &lt;- meth_gravity } 2.6 Save Dataset Once completed, we then want to save this dataset for future use. Creating this data (in particular, the gravity variables) is time consuming and so we do not want to have to frequently re-run this code. rm(list=setdiff(ls(), &quot;data&quot;)) write.csv(data, &quot;Final_Dataset.csv&quot;) "],
["map.html", "Chapter 3 Mapping Variables 3.1 Synthetic Opioid Overdose 3.2 Synthetic Opioid Overdose Gravity 3.3 Heroin Overdose 3.4 Meth Overdose 3.5 Cocaine Overdose", " Chapter 3 Mapping Variables Prior to running analyses, it is of interest to map out some variables to see how they distribute across the United States. 3.1 Synthetic Opioid Overdose 3.2 Synthetic Opioid Overdose Gravity 3.3 Heroin Overdose 3.4 Meth Overdose 3.5 Cocaine Overdose "],
["linreg.html", "Chapter 4 Linear Regression 4.1 In This Section 4.2 Imputation and Transformation 4.3 Neighboring Counties 4.4 A Simple Regression Model 4.5 A Multiple Regression Model 4.6 In Conclusion", " Chapter 4 Linear Regression 4.1 In This Section We want to see how effectively we can predict 2017 county-level synthetic opioid death rates using a simple linear regression approach. 4.2 Imputation and Transformation For some of our potential variables, we want to impute some missing values. For a few, as well, such as population density, we also want to log transform them. 4.3 Neighboring Counties We also want to generate a few additional variables that articulate the impact of synthetic opioid on neighboring counties. While we previously generated gravity variables, these are a function of both a county’s death rate and their neighbors. We want to generate variable(s) which simply articulate neighboring county rates. Here we create two new variables, one which measures the highest synthetic opioid overdose death rate of a county’s neighbors (continuous) and a second variable which measures (T/F) if any of a county’s neighbors exceed a certain threshold. 4.4 A Simple Regression Model 4.4.1 Defining Our Initial Regression Equation To begin, we start with a very simple model. We presume that the previous years synthetic opioid death rate will be highly predictive of the next year. We imagine that annual changes will be a function of time (as the epidemic has spread, the dynamics of the epidemic have changed) as well as the proximity of the epidemic. As such, we have included both year (continuous) and whether a neighbor had a death rate of 10 or more the previous year (T/F) as interaction terms. 4.4.2 Running the Model and Predicting So, first we need our training data. Essentially, our goal is to see if we can use 2016 county-level data to predict 2017 synthetic opioid death rates. So our training data will be all data prior to this. We will train a linear regression model on this data. Then we will use the model on the 2016 dataset to predict 2017 synthetic death rate. 4.4.3 Evaluating Model Performance 4.4.3.1 Continuous Metrics First, we want to see how well the model did at predicting the 2017 synthetic opioid crude deat rate. Here we present a series of metrics which reflect on the performance. ## R Squared RMSE MAE Pearson&#39;s R Spearman&#39;s rho ## 1 0.6449826 4.979847 2.446574 0.8278455 0.9015019 4.4.3.2 Categorical Metrics We predicted a continuous outcome, but it is of interest to simply ask if our model correctly identified counties whose death rate exceeded a certain threshold. For example, it may be of interest to see how well our model identified counties whose deeath rate exceeded 10 per 100,000. The following code calculates this, identifying true positives, true negatives, false positives, false negatives, and accompanying statistics of accuracy. ## ## FALSE TRUE ## FALSE 2330 422 ## TRUE 35 355 ## True Positives False Positives True Negatives False Negatives PPV NPV Senisitivity Specificity Accuracy ## 1 355 422 2330 35 0.4568855 0.9852008 0.9102564 0.846657 0.8545512 4.5 A Multiple Regression Model 4.5.1 Defining Our Initial Regression Equation Now, it is also of interest to see if including a series of covariates to our model may improve performance. For starters, we are just going to throw a bunch in and see. Then we will replicate what we did for the simple model. 4.5.2 Running the Model and Predicting So, first we need our training data. Essentially, our goal is to see if we can use 2016 county-level data to predict 2017 synthetic opioid death rates. So our training data will be all data prior to this. We will train a linear regression model on this data. Then we will use the model on the 2016 dataset to predict 2017 synthetic death rate. 4.5.3 Evaluating Model Performance 4.5.3.1 Continuous Metrics First, we want to see how well the model did at predicting the 2017 synthetic opioid crude deat rate. Here we present a series of metrics which reflect on the performance. ## R Squared RMSE MAE Pearson&#39;s R Spearman&#39;s rho ## 1 0.6854001 4.6387 2.005406 0.830342 0.9051792 4.5.3.2 Categorical Metrics We predicted a continuous outcome, but it is of interest to simply ask if our model correctly identified counties whose death rate exceeded a certain threshold. For example, it may be of interest to see how well our model identified counties whose deeath rate exceeded 10 per 100,000. The following code calculates this, identifying true positives, true negatives, false positives, false negatives, and accompanying statistics of accuracy. ## ## FALSE TRUE ## FALSE 2544 208 ## TRUE 40 350 ## True Positives False Positives True Negatives False Negatives PPV NPV Senisitivity Specificity Accuracy ## 1 350 208 2544 40 0.6272401 0.9845201 0.8974359 0.9244186 0.9210694 4.6 In Conclusion We see (when looking at our categorical outcomes) that the simple model performs rather well! Identifying a majority of the actual locations where the synthetic opioid death rate was at higher levels. We see though, that when we incorporate covariates, the false positive count is cut in half, indicating much much better performance overall. As well, continuous metrics indicate the inclusion of covariates improves model performance. "],
["otherML.html", "Chapter 5 Other Regression Strategies 5.1 Random Forest", " Chapter 5 Other Regression Strategies A question of interest is whether or not some other commonly used regression techniques perform better than linear regression. Here we examine this. 5.1 Random Forest A commonly used approach is random forest. Let us replicate everything we did with linear regression. 5.1.1 Defining Our Initial Regression Equation Now, it is also of interest to see if including a series of covariates to our model may improve performance. For starters, we are just going to throw a bunch in and see. Then we will replicate what we did for the simple model. 5.1.2 Running the Model and Predicting So, first we need our training data. Essentially, our goal is to see if we can use 2016 county-level data to predict 2017 synthetic opioid death rates. So our training data will be all data prior to this. We will train a linear regression model on this data. Then we will use the model on the 2016 dataset to predict 2017 synthetic death rate. 5.1.3 Evaluating Model Performance 5.1.3.1 Continuous Metrics First, we want to see how well the model did at predicting the 2017 synthetic opioid crude deat rate. Here we present a series of metrics which reflect on the performance. ## R Squared RMSE MAE Pearson&#39;s R Spearman&#39;s rho ## 1 0.6521824 4.877551 1.937538 0.8092943 0.9208151 5.1.3.2 Categorical Metrics We predicted a continuous outcome, but it is of interest to simply ask if our model correctly identified counties whose death rate exceeded a certain threshold. For example, it may be of interest to see how well our model identified counties whose deeath rate exceeded 10 per 100,000. The following code calculates this, identifying true positives, true negatives, false positives, false negatives, and accompanying statistics of accuracy. ## ## FALSE TRUE ## FALSE 2566 186 ## TRUE 51 339 ## True Positives False Positives True Negatives False Negatives PPV NPV Senisitivity Specificity Accuracy ## 1 339 186 2566 51 0.6457143 0.980512 0.8692308 0.9324128 0.9245703 "]
]
=======
[
["index.html", "Predicting Synthetic Opioid Outbreaks Chapter 1 What Is In This Book?", " Predicting Synthetic Opioid Outbreaks Charles Marks 2020-01-15 Chapter 1 What Is In This Book? "],
["dataprep.html", "Chapter 2 Data Preparation 2.1 CDC Wonder Data 2.2 American Community Survey 2.3 Additional Variables 2.4 Defining Outcomes 2.5 Neighboring County Variables (including Gravity) 2.6 Save Dataset", " Chapter 2 Data Preparation Prior to undertaking the analysis, we need to prepare our data. We are looking at annual county-level statistics, so here we will create an observation for each countyXyear for all US counties (n = 3143) and all years between 2010 and 2017. To replicate this code, the data has been made available in the following repository. 2.1 CDC Wonder Data 2.1.1 Upload the Datas We will start this process by using data downloaded from the CDC Wonder database. Wonder allows users to extract annual, county-level overdose numbers overall and for specific drugs (ie heroin, cocaine, synthetic opioids, et al). Here we upload datasets extracted from the CDC Wonder database to create our initial dataset. ## load the data synthetic_opioid_data &lt;- read.table(file = &quot;Data/Synthetic_Opioid_Overdose_By_County_2010-2017.txt&quot;, sep = &#39;\\t&#39;, header = TRUE) heroin_data &lt;- read.table(file = &quot;Data/Heroin_Overdose_By_County_2010-2017.txt&quot;, sep = &#39;\\t&#39;, header = TRUE) cocaine_data &lt;- read.table(file = &quot;Data/Cocaine_Overdose_By_County_2010-2017.txt&quot;, sep = &#39;\\t&#39;, header = TRUE) meth_data &lt;- read.table(file = &quot;Data/Meth_Overdose_By_County_2010-2017.txt&quot;, sep = &#39;\\t&#39;, header = TRUE) ## clean the data a little bit synthetic_opioid_data$County &lt;- as.character(synthetic_opioid_data$County) synthetic_opioid_data$Deaths &lt;- (as.character(synthetic_opioid_data$Deaths)) synthetic_opioid_data$Deaths[synthetic_opioid_data$Deaths == &quot;Suppressed&quot;] &lt;- -99 synthetic_opioid_data$Deaths &lt;- (as.numeric(synthetic_opioid_data$Deaths)) synthetic_opioid_data$Population &lt;- as.numeric(as.character(synthetic_opioid_data$Population)) heroin_data$County &lt;- as.character(heroin_data$County) heroin_data$Deaths &lt;- (as.character(heroin_data$Deaths)) heroin_data$Deaths[heroin_data$Deaths == &quot;Suppressed&quot;] &lt;- -99 heroin_data$Deaths &lt;- (as.numeric(heroin_data$Deaths)) heroin_data$Population &lt;- as.numeric(as.character(heroin_data$Population)) cocaine_data$County &lt;- as.character(cocaine_data$County) cocaine_data$Deaths &lt;- (as.character(cocaine_data$Deaths)) cocaine_data$Deaths[cocaine_data$Deaths == &quot;Suppressed&quot;] &lt;- -99 cocaine_data$Deaths &lt;- (as.numeric(cocaine_data$Deaths)) cocaine_data$Population &lt;- as.numeric(as.character(cocaine_data$Population)) meth_data$County &lt;- as.character(meth_data$County) meth_data$Deaths &lt;- (as.character(meth_data$Deaths)) meth_data$Deaths[meth_data$Deaths == &quot;Suppressed&quot;] &lt;- -99 meth_data$Deaths &lt;- (as.numeric(meth_data$Deaths)) meth_data$Population &lt;- as.numeric(as.character(meth_data$Population)) ## merge into one file data &lt;- synthetic_opioid_data[c(2:4,7:6)] data$heroin_deaths &lt;- NA data$cocaine_deaths &lt;- NA data$meth_deaths &lt;- NA for(county_id in unique(data$County.Code)){ for(year in unique(data$Year)){ data$heroin_deaths[data$County.Code == county_id &amp; data$Year == year] &lt;- heroin_data$Deaths[heroin_data$County.Code == county_id &amp; heroin_data$Year == year] data$cocaine_deaths[data$County.Code == county_id &amp; data$Year == year] &lt;- cocaine_data$Deaths[cocaine_data$County.Code == county_id &amp; cocaine_data$Year == year] data$meth_deaths[data$County.Code == county_id &amp; data$Year == year] &lt;- meth_data$Deaths[meth_data$County.Code == county_id &amp; meth_data$Year == year] } } colnames(data) &lt;- c(&quot;county_name&quot;,&quot;county_code&quot;,&quot;year&quot;,&quot;population&quot;,&quot;synthetic_opioid_deaths&quot;,&quot;heroin_deaths&quot;,&quot;cocaine_deaths&quot;,&quot;meth_deaths&quot;) data &lt;- data[!is.na(data$population),] 2.1.2 Imputing Missing Data The CDC suppresses any value beneath 10 (ie if a county had 6 overdose deaths in a given year, the CDC just reports suppressed) and so we need to find a way to impute this value. The CDC recommends a procedure which we update. Essentially for a given state \\(S\\) in a given year \\(Y\\), we take the number of overdoses \\(O\\) in that year and subtract from it all of the non-suppressed county counts \\(o_i\\). The remaining number of deaths, \\(O - \\sum{o_i}\\) is then distributed to the “Suppressed” counties on a population basis. ## load the state data synthetic_opioid_data &lt;- read.table(file = &quot;Data/Synthetic_Opioid_Overdose_By_State_2010-2017.txt&quot;, sep = &#39;\\t&#39;, header = TRUE) heroin_data &lt;- read.table(file = &quot;Data/Heroin_Overdose_By_State_2010-2017.txt&quot;, sep = &#39;\\t&#39;, header = TRUE) cocaine_data &lt;- read.table(file = &quot;Data/Cocaine_Overdose_By_State_2010-2017.txt&quot;, sep = &#39;\\t&#39;, header = TRUE) meth_data &lt;- read.table(file = &quot;Data/Meth_Overdose_By_State_2010-2017.txt&quot;, sep = &#39;\\t&#39;, header = TRUE) ## clean the data a little bit synthetic_opioid_data$State &lt;- as.character(synthetic_opioid_data$State) synthetic_opioid_data$Deaths &lt;- (as.character(synthetic_opioid_data$Deaths)) synthetic_opioid_data$Deaths[synthetic_opioid_data$Deaths == &quot;Suppressed&quot;] &lt;- -99 synthetic_opioid_data$Deaths &lt;- (as.numeric(synthetic_opioid_data$Deaths)) heroin_data$State &lt;- as.character(heroin_data$State) heroin_data$Deaths &lt;- (as.character(heroin_data$Deaths)) heroin_data$Deaths[heroin_data$Deaths == &quot;Suppressed&quot;] &lt;- -99 heroin_data$Deaths &lt;- (as.numeric(heroin_data$Deaths)) cocaine_data$State &lt;- as.character(cocaine_data$State) cocaine_data$Deaths &lt;- (as.character(cocaine_data$Deaths)) cocaine_data$Deaths[cocaine_data$Deaths == &quot;Suppressed&quot;] &lt;- -99 cocaine_data$Deaths &lt;- (as.numeric(cocaine_data$Deaths)) meth_data$State &lt;- as.character(meth_data$State) meth_data$Deaths &lt;- (as.character(meth_data$Deaths)) meth_data$Deaths[meth_data$Deaths == &quot;Suppressed&quot;] &lt;- -99 meth_data$Deaths &lt;- (as.numeric(meth_data$Deaths)) ## now we need to undertake the imputation procedure for(state_id in unique(synthetic_opioid_data$State.Code)){ for(year in unique(synthetic_opioid_data$Year)){ ## we first want to get the total number of deaths for the state total_synthetic_opioid_deaths &lt;- synthetic_opioid_data$Deaths[synthetic_opioid_data$State.Code == state_id &amp; synthetic_opioid_data$Year == year] total_heroin_deaths &lt;- heroin_data$Deaths[heroin_data$State.Code == state_id &amp; heroin_data$Year == year] total_cocaine_deaths &lt;- cocaine_data$Deaths[cocaine_data$State.Code == state_id &amp; cocaine_data$Year == year] total_meth_deaths &lt;- meth_data$Deaths[meth_data$State.Code == state_id &amp; meth_data$Year == year] ## then we want to subtract the number of deaths recorded ## and extract the counties that were suppressed county_data &lt;- data[data$county_code &gt;= state_id*1000 &amp; data$county_code &lt; (state_id*1000 + 1000) &amp; data$year == year,] synthetic_opioid_counties_suppressed &lt;- c() heroin_counties_suppressed &lt;- c() cocaine_counties_suppressed &lt;- c() meth_counties_suppressed &lt;- c() for(county_id in unique(county_data$county_code)){ ## synthetic opioid so_death &lt;- county_data$synthetic_opioid_deaths[county_data$county_code == county_id] if(so_death == -99){ synthetic_opioid_counties_suppressed &lt;- c(synthetic_opioid_counties_suppressed, county_id) }else{ total_synthetic_opioid_deaths &lt;- total_synthetic_opioid_deaths - so_death } ## heroin h_death &lt;- county_data$heroin_deaths[county_data$county_code == county_id] if(h_death == -99){ heroin_counties_suppressed &lt;- c(heroin_counties_suppressed, county_id) }else{ total_heroin_deaths &lt;- total_heroin_deaths - h_death } ## cocaine c_death &lt;- county_data$cocaine_deaths[county_data$county_code == county_id] if(c_death == -99){ cocaine_counties_suppressed &lt;- c(cocaine_counties_suppressed, county_id) }else{ total_cocaine_deaths &lt;- total_cocaine_deaths - c_death } ## meth m_death &lt;- county_data$meth_deaths[county_data$county_code == county_id] if(m_death == -99){ meth_counties_suppressed &lt;- c(meth_counties_suppressed, county_id) }else{ total_meth_deaths &lt;- total_meth_deaths - m_death } } ## now we get the population rate of deaths for suppressed counties synthetic_opioid_suppressed_pop &lt;- 0 heroin_suppressed_pop &lt;- 0 cocaine_suppressed_pop &lt;- 0 meth_suppressed_pop &lt;- 0 for(county_id in synthetic_opioid_counties_suppressed){ synthetic_opioid_suppressed_pop &lt;- synthetic_opioid_suppressed_pop + county_data$population[county_data$county_code == county_id] } for(county_id in heroin_counties_suppressed){ heroin_suppressed_pop &lt;- heroin_suppressed_pop + county_data$population[county_data$county_code == county_id] } for(county_id in cocaine_counties_suppressed){ cocaine_suppressed_pop &lt;- cocaine_suppressed_pop + county_data$population[county_data$county_code == county_id] } for(county_id in meth_counties_suppressed){ meth_suppressed_pop &lt;- meth_suppressed_pop + county_data$population[county_data$county_code == county_id] } synthetic_opioid_rate &lt;- 0 if(synthetic_opioid_suppressed_pop &gt; 0){ synthetic_opioid_rate &lt;- total_synthetic_opioid_deaths/synthetic_opioid_suppressed_pop } heroin_rate &lt;- 0 if(heroin_suppressed_pop &gt; 0){ heroin_rate &lt;- total_heroin_deaths/heroin_suppressed_pop } cocaine_rate &lt;- 0 if(cocaine_suppressed_pop &gt; 0){ cocaine_rate &lt;- total_cocaine_deaths/cocaine_suppressed_pop } meth_rate &lt;- 0 if(meth_suppressed_pop &gt; 0){ meth_rate &lt;- total_meth_deaths/meth_suppressed_pop } if(synthetic_opioid_rate &lt; 0){ synthetic_opioid_rate &lt;- 0} if(heroin_rate &lt; 0){ heroin_rate &lt;- 0} if(cocaine_rate &lt; 0){ cocaine_rate &lt;- 0} if(meth_rate &lt; 0){ meth_rate &lt;- 0} ## we now want to apply these rates to calculate an imputed value for each suppressed county in the actual data set ## note that we know that the crude number does not exceed 9 and thus we use the min() function to cap the value at 9 for(county_id in unique(county_data$county_code)){ county_pop &lt;- data$population[data$county_code == county_id &amp; data$year == year] if(data$synthetic_opioid_deaths[data$county_code == county_id &amp; data$year == year] == -99){ data$synthetic_opioid_deaths[data$county_code == county_id &amp; data$year == year] &lt;- min(county_pop*synthetic_opioid_rate,9) } if(data$heroin_deaths[data$county_code == county_id &amp; data$year == year] == -99){ data$heroin_deaths[data$county_code == county_id &amp; data$year == year] &lt;- min(county_pop*heroin_rate,9) } if(data$cocaine_deaths[data$county_code == county_id &amp; data$year == year] == -99){ data$cocaine_deaths[data$county_code == county_id &amp; data$year == year] &lt;- min(county_pop*cocaine_rate,9) } if(data$meth_deaths[data$county_code == county_id &amp; data$year == year] == -99){ data$meth_deaths[data$county_code == county_id &amp; data$year == year] &lt;- min(county_pop*meth_rate,9) } } } } 2.1.3 Calculating Crude Rates Now, with the imputed values we are then able to calculate the crude deaths rates of each county (per 100,000 people). This is done by dividing the number of deaths by the size of population and then multiplying this value by 100,000. data$synthetic_opioid_crude_death_rate &lt;- 100000*(data$synthetic_opioid_deaths/data$population) data$heroin_crude_death_rate &lt;- 100000*(data$heroin_deaths/data$population) data$cocaine_crude_death_rate &lt;- 100000*(data$cocaine_deaths/data$population) data$meth_crude_death_rate &lt;- 100000*(data$meth_deaths/data$population) 2.2 American Community Survey We would also like to add some demographic data, which is available from the ACS. This dataset has been created by merging multiple ACS data files, the code for which is contained in the appendix. ACS &lt;- read.csv(&quot;Data/Updated_ACS_data.csv&quot;, header = T) for(i in 1:nrow(ACS)){ for(j in 1:ncol(ACS)){ if(is.na(ACS[i,j])){ ACS[i,j] &lt;- -999 } } } data$unemployment_rate &lt;- NA data$median_household_income &lt;- NA data$mean_household_income &lt;- NA data$proportion_poverty &lt;- NA data$proportion_uninsured &lt;- NA data$proportion_homes_no_vehicle &lt;- NA data$proportion_homeowners_35perc_income &lt;- NA data$proportion_renters_35perc_income &lt;- NA data$proportion_white &lt;- NA data$proportion_black &lt;- NA data$proportion_american_indian_alaska_native &lt;- NA data$proportion_asian &lt;- NA data$proportion_native_hawaiian_pacific_islander &lt;- NA data$proportion_male &lt;- NA data$proportion_high_school_or_greater &lt;- NA data$proportion_bachelors_or_greater &lt;- NA for(i in 1:nrow(data)){ if(data$county_code[i] %in% c(2201,2232,2280)){} ## three Alaskan counties which don&#39;t have data. else{ data$unemployment_rate[i] &lt;- ACS$Unemployment_Rate[ACS$ID == data$county_code[i] &amp; ACS$Year == data$year[i]] data$median_household_income[i] &lt;- ACS$Median_Household_Income[ACS$ID == data$county_code[i] &amp; ACS$Year == data$year[i]] data$mean_household_income[i] &lt;- ACS$Mean_Household_Income[ACS$ID == data$county_code[i] &amp; ACS$Year == data$year[i]] data$proportion_poverty[i] &lt;- ACS$Proportion_Poverty[ACS$ID == data$county_code[i] &amp; ACS$Year == data$year[i]] data$proportion_uninsured[i] &lt;- ACS$Proportion_Uninsured[ACS$ID == data$county_code[i] &amp; ACS$Year == data$year[i]] data$proportion_homes_no_vehicle[i] &lt;- ACS$Proportion_Homes_No_Vehicle[ACS$ID == data$county_code[i] &amp; ACS$Year == data$year[i]] data$proportion_homeowners_35perc_income[i] &lt;- ACS$Proportion_Homeowners_35Perc_Income_on_Home[ACS$ID == data$county_code[i] &amp; ACS$Year == data$year[i]] data$proportion_renters_35perc_income[i] &lt;- ACS$Proportion_Renters_35Perc_Income_on_Rent[ACS$ID == data$county_code[i] &amp; ACS$Year == data$year[i]] data$proportion_white[i] &lt;- ACS$Proportion_White[ACS$ID == data$county_code[i] &amp; ACS$Year == data$year[i]] data$proportion_black[i] &lt;- ACS$Proportion_Black[ACS$ID == data$county_code[i] &amp; ACS$Year == data$year[i]] data$proportion_american_indian_alaska_native[i] &lt;- ACS$Proportion_American_Indian_Alaska_Native[ACS$ID == data$county_code[i] &amp; ACS$Year == data$year[i]] data$proportion_asian[i] &lt;- ACS$Proportion_Asian[ACS$ID == data$county_code[i] &amp; ACS$Year == data$year[i]] data$proportion_native_hawaiian_pacific_islander[i] &lt;- ACS$Proportion_Native_Hawaiian_Pacific_Islander[ACS$ID == data$county_code[i] &amp; ACS$Year == data$year[i]] data$proportion_male[i] &lt;- ACS$Proportion_Male[ACS$ID == data$county_code[i] &amp; ACS$Year == data$year[i]] data$proportion_high_school_or_greater[i] &lt;- ACS$Proportion_High_School_or_Greater[ACS$ID == data$county_code[i] &amp; ACS$Year == data$year[i]] data$proportion_bachelors_or_greater[i] &lt;- ACS$Proportion_Bachelors_Degree_or_Greater[ACS$ID == data$county_code[i] &amp; ACS$Year == data$year[i]] } } for(i in 1:nrow(ACS)){ for(j in 1:ncol(ACS)){ if(ACS[i,j] == -999){ ACS[i,j] &lt;- NA } } } 2.3 Additional Variables 2.3.1 Hepatitis C Mortality (CDC Wonder) We used a very similar approach for this variable as for our specific drug use mortalities, using state level estimates to impute suppressed county numbers. hepatitis_state_data &lt;- read.table(file = &quot;Data/Hepatitis_C_Mortality_By_State.txt&quot;, sep = &#39;\\t&#39;, header = TRUE) hepatitis_county_data &lt;- read.table(file = &quot;Data/Hepatitis_C_Mortality_By_County.txt&quot;, sep = &#39;\\t&#39;, header = TRUE) ## clean the data a little bit hepatitis_state_data$State &lt;- as.character(hepatitis_state_data$State) hepatitis_state_data$Deaths &lt;- (as.character(hepatitis_state_data$Deaths)) hepatitis_state_data$Deaths[hepatitis_state_data$Deaths == &quot;Suppressed&quot;] &lt;- -99 hepatitis_state_data$Deaths &lt;- (as.numeric(hepatitis_state_data$Deaths)) hepatitis_county_data$County &lt;- as.character(hepatitis_county_data$County) hepatitis_county_data$Deaths &lt;- (as.character(hepatitis_county_data$Deaths)) hepatitis_county_data$Deaths[hepatitis_county_data$Deaths == &quot;Suppressed&quot;] &lt;- -99 hepatitis_county_data$Deaths &lt;- (as.numeric(hepatitis_county_data$Deaths)) hepatitis_county_data$Population &lt;- as.numeric(as.character(hepatitis_county_data$Population)) ## now we need to undertake the imputation procedure for(state_id in unique(hepatitis_state_data$State.Code)){ for(year in unique(hepatitis_state_data$Year)){ ## we first want to get the total number of deaths for the state total_hepatitis_deaths &lt;- hepatitis_state_data$Deaths[hepatitis_state_data$State.Code == state_id &amp; hepatitis_state_data$Year == year] ## then we want to subtract the number of deaths recorded ## and extract the counties that were suppressed county_data &lt;- hepatitis_county_data[hepatitis_county_data$County.Code &gt;= state_id*1000 &amp; hepatitis_county_data$County.Code &lt; (state_id*1000 + 1000) &amp; hepatitis_county_data$Year == year,] counties_suppressed &lt;- c() for(county_id in unique(county_data$County.Code)){ death &lt;- county_data$Deaths[county_data$County.Code == county_id] if(is.na(death)){ } else if(death == -99){ counties_suppressed &lt;- c(counties_suppressed, county_id) }else{ total_hepatitis_deaths &lt;- total_hepatitis_deaths - death } } ## now we get the population rate of deaths for suppressed counties suppressed_pop &lt;- 0 for(county_id in counties_suppressed){ suppressed_pop &lt;- suppressed_pop + county_data$Population[county_data$County.Code == county_id] } death_rate &lt;- 0 if(suppressed_pop &gt; 0){ death_rate &lt;- total_hepatitis_deaths/suppressed_pop } if(death_rate &lt; 0){ death_rate &lt;- 0} ## we now want to apply these rates to calculate an imputed value for each suppressed county in the actual data set ## note that we know that the crude number does not exceed 9 and thus we use the min() function to cap the value at 9 for(county_id in unique(county_data$County.Code)){ county_pop &lt;- county_data$Population[county_data$County.Code == county_id] if(is.na(county_data$Deaths[county_data$County.Code == county_id])){ }else if(county_data$Deaths[county_data$County.Code == county_id] == -99){ hepatitis_county_data$Deaths[hepatitis_county_data$County.Code == county_id &amp; hepatitis_county_data$Year == year] &lt;- min(county_pop*death_rate,9) } } } } ## so now we want to merge this data into our final dataset ## note that we need to convert this into an actual rate when we do this data$hep_c_mortality_rate &lt;- NA for(i in 1:nrow(data)){ year &lt;- data$year[i] county &lt;- data$county_code[i] numbers_of_deaths &lt;- hepatitis_county_data$Deaths[hepatitis_county_data$County.Code == county &amp; hepatitis_county_data$Year == year] population &lt;- data$population[i] hepatitis_mortality_rate &lt;- 100000*(numbers_of_deaths/population) data$hep_c_mortality_rate[i] &lt;- hepatitis_mortality_rate } 2.3.2 Urbanicity urbanicity &lt;- read.csv(&quot;Data/Urbanicity.csv&quot;, header = T) data$urbanicity &lt;- NA for(id in unique(data$county_code)){ urban &lt;- urbanicity$X2013.code[urbanicity$ï..FIPS.code == id] data$urbanicity[data$county_code == id] &lt;- urban } 2.3.3 Opioid Prescribing https://www.cdc.gov/drugoverdose/maps/rxrate-maps.html prescribing &lt;- read.csv(&quot;Data/Opioid_Prescribing_per_100.csv&quot;, header = T) prescribing$Rate_per_100 &lt;- as.numeric(as.character(prescribing$Rate_per_100)) data$opioid_prescriptions_per_100 &lt;- NA for(i in 1:nrow(data)){ year &lt;- data$year[i] county &lt;- data$county_code[i] prescriptions &lt;- prescribing$Rate_per_100[prescribing$State.County.FIPS.Code == county &amp; prescribing$Year == year] if(length(prescriptions) &gt; 0){ data$opioid_prescriptions_per_100[i] &lt;- prescriptions } } ### Need to Impute the missing data ### Lets match on state and urbanicity? for(year in 2010:2017){ for(state in 1:56){ counties &lt;- data[data$year == year &amp; data$county_code &gt;= state*1000 &amp; data$county_code &lt; (state + 1)*1000,] for(urbanicity in 1:6){ urb_cnty &lt;- counties[counties$urbanicity == urbanicity,] rate &lt;- mean(urb_cnty$opioid_prescriptions_per_100, na.rm = T) data$opioid_prescriptions_per_100[data$urbanicity == urbanicity &amp; data$county_code %in% urb_cnty$county_code &amp; data$year == year &amp; is.na(data$opioid_prescriptions_per_100)] &lt;- rate } } } 2.3.4 Population Density land_area &lt;- read.csv(&quot;Data/Land_Area.csv&quot;, header = T) data$population_density &lt;- NA for(id in unique(data$county_code)){ if(id %in% c(2201,2232,2280)){} ## three Alaskan counties which don&#39;t have data. else{ la &lt;- land_area$Land_Area[land_area$FIPS == id] subset &lt;- data[data$county_code == id,] for(year in unique(subset$year)){ population &lt;- subset$population[subset$year == year] pop_density &lt;- population/la data$population_density[data$county_code == id &amp; data$year == year] &lt;- pop_density } } } data$log_population_density &lt;- log(data$population_density) 2.3.5 Police Violence police_violence &lt;- read.csv(&quot;Data/annual_police_violence_by_county.csv&quot;, header = T) data$police_violence &lt;- NA for(i in 1:nrow(data)){ year &lt;- data$year[i] fips &lt;- data$county_code[i] if(year == 2010){ killings &lt;- police_violence$deaths_2010[police_violence$county_fips == fips] if(length(killings) &gt; 0 &amp;&amp; killings &gt; 0){ data$police_violence[i] &lt;- T }else if(length(killings) &gt;0 &amp;&amp; killings == 0){ data$police_violence[i] &lt;- F } }else if(year == 2011){ killings &lt;- police_violence$deaths_2011[police_violence$county_fips == fips] if(length(killings) &gt; 0 &amp;&amp; killings &gt; 0){ data$police_violence[i] &lt;- T }else if(length(killings) &gt;0 &amp;&amp; killings == 0){ data$police_violence[i] &lt;- F } }else if(year == 2012){ killings &lt;- police_violence$deaths_2012[police_violence$county_fips == fips] if(length(killings) &gt; 0 &amp;&amp; killings &gt; 0){ data$police_violence[i] &lt;- T }else if(length(killings) &gt;0 &amp;&amp; killings == 0){ data$police_violence[i] &lt;- F } }else if(year == 2013){ killings &lt;- police_violence$deaths_2013[police_violence$county_fips == fips] if(length(killings) &gt; 0 &amp;&amp; killings &gt; 0){ data$police_violence[i] &lt;- T }else if(length(killings) &gt;0 &amp;&amp; killings == 0){ data$police_violence[i] &lt;- F } }else if(year == 2014){ killings &lt;- police_violence$deaths_2014[police_violence$county_fips == fips] if(length(killings) &gt; 0 &amp;&amp; killings &gt; 0){ data$police_violence[i] &lt;- T }else if(length(killings) &gt;0 &amp;&amp; killings == 0){ data$police_violence[i] &lt;- F } }else if(year == 2015){ killings &lt;- police_violence$deaths_2015[police_violence$county_fips == fips] if(length(killings) &gt; 0 &amp;&amp; killings &gt; 0){ data$police_violence[i] &lt;- T }else if(length(killings) &gt;0 &amp;&amp; killings == 0){ data$police_violence[i] &lt;- F } }else if(year == 2016){ killings &lt;- police_violence$deaths_2016[police_violence$county_fips == fips] if(length(killings) &gt; 0 &amp;&amp; killings &gt; 0){ data$police_violence[i] &lt;- T }else if(length(killings) &gt;0 &amp;&amp; killings == 0){ data$police_violence[i] &lt;- F } }else if(year == 2017){ killings &lt;- police_violence$deaths_2017[police_violence$county_fips == fips] if(length(killings) &gt; 0 &amp;&amp; killings &gt; 0){ data$police_violence[i] &lt;- T }else if(length(killings) &gt;0 &amp;&amp; killings == 0){ data$police_violence[i] &lt;- F } } } 2.3.6 Road Access &amp; Urgent Care Facilities hospitals &lt;- read.csv(&quot;Data/roads_urgent_care.csv&quot;, header = T) data$road_access &lt;- NA data$urgent_care &lt;- NA for(id in unique(data$county_code)){ road_access &lt;- hospitals$roads_access[hospitals$GEOID == id] urgent_care &lt;- hospitals$urgent_care[hospitals$GEOID == id] if(length(road_access) &gt; 0 &amp;&amp; road_access == &quot;yes&quot;){ road_access &lt;- T } else{ road_access&lt;- F} if(length(urgent_care) &gt; 0 &amp;&amp; urgent_care == &quot;yes&quot;){ urgent_care &lt;- T }else{urgent_care &lt;- F} data$road_access[data$county_code == id] &lt;- road_access data$urgent_care[data$county_code == id] &lt;- urgent_care } 2.4 Defining Outcomes So, we have established the annual data, but, because we are looking at projecting into the future, we need to pair observations with future outcomes. Essentially, we will pair each observation with the synthetic opioid death rates corresponding to one year, two years, and three years into the future. This is of interest because mortality data isn’t typically available in time to make next year predictions. We can use these to show the importance of releasing data swiftly. ## for now we are focusing on synthetic opioids ## we will create two variables, next year and in two years data$next_year_synthetic_opioid_death_rate &lt;- NA data$two_year_out_synthetic_opioid_death_rate &lt;- NA for(fips in unique(data$county_code)){ for(year in 2010:2016){ next_year &lt;- data$synthetic_opioid_crude_death_rate[data$year == year + 1 &amp; data$county_code == fips] if(length(next_year) &gt; 0){ data$next_year_synthetic_opioid_death_rate[data$year == year &amp; data$county_code == fips] &lt;- next_year } if(year &lt; 2016){ second_year &lt;- data$synthetic_opioid_crude_death_rate[data$year == year + 2 &amp; data$county_code == fips] if(length(second_year) &gt; 0){ data$two_year_out_synthetic_opioid_death_rate[data$year == year &amp; data$county_code == fips] &lt;- second_year } } } } 2.5 Neighboring County Variables (including Gravity) Of interest is considering how the presence of overdose in neighboring counties impacts overdose in a given county. A gravity approach is considered appropriate so here we will create gravity metrics for each of the four classes of overdose we have defined in our dataset (synthetic opioids, heroin, meth, cocaine). We multiply the overdose rates of two counties and divide by the distance to get the gravity between two counties. Each county’s gravity metric is the sum of all gravity scores. rm(list=setdiff(ls(), &quot;data&quot;)) distances &lt;- read.csv(&quot;Data/County_Distances.csv&quot;, header = T) data$synthetic_opiod_gravity &lt;- NA data$heroin_gravity &lt;- NA data$cocaine_gravity &lt;- NA data$meth_gravity &lt;- NA for(i in 1:nrow(data)){ print(i) fips &lt;- data$county_code[i] year &lt;- data$year[i] synth_od &lt;- data$synthetic_opioid_crude_death_rate[i] heroin_od &lt;- data$heroin_crude_death_rate[i] cocaine_od &lt;- data$cocaine_crude_death_rate[i] meth_od &lt;- data$meth_crude_death_rate[i] dist &lt;- distances[distances$county1 == fips &amp; distances$mi_to_county &lt; 200,] synth_gravity &lt;- 0 heroin_gravity &lt;- 0 cocaine_gravity &lt;- 0 meth_gravity &lt;- 0 for(j in 1:nrow(dist)){ fips2 &lt;- dist$county2[j] d &lt;- dist$mi_to_county[j] synth_od2 &lt;- data$synthetic_opioid_crude_death_rate[data$county_code == fips2 &amp; data$year == year] heroin_od2 &lt;- data$heroin_crude_death_rate[data$county_code == fips2 &amp; data$year == year] cocaine_od2 &lt;- data$cocaine_crude_death_rate[data$county_code == fips2 &amp; data$year == year] meth_od2 &lt;- data$meth_crude_death_rate[data$county_code == fips2 &amp; data$year == year] if(length(synth_od2) &gt; 0){ synth_gravity &lt;- synth_gravity + ((synth_od*synth_od2)/(d^2)) } if(length(heroin_od2) &gt; 0){ heroin_gravity &lt;- heroin_gravity + ((heroin_od*heroin_od2)/(d^2)) } if(length(cocaine_od2) &gt; 0){ cocaine_gravity &lt;- cocaine_gravity + ((cocaine_od*cocaine_od2)/(d^2)) } if(length(meth_od2) &gt; 0){ meth_gravity &lt;- meth_gravity + ((meth_od*meth_od2)/(d^2)) } } data$synthetic_opiod_gravity[i] &lt;- synth_gravity data$heroin_gravity[i] &lt;- heroin_gravity data$cocaine_gravity[i] &lt;- cocaine_gravity data$meth_gravity[i] &lt;- meth_gravity } 2.6 Save Dataset Once completed, we then want to save this dataset for future use. Creating this data (in particular, the gravity variables) is time consuming and so we do not want to have to frequently re-run this code. rm(list=setdiff(ls(), &quot;data&quot;)) write.csv(data, &quot;Final_Dataset.csv&quot;) "],
["map.html", "Chapter 3 Mapping Variables 3.1 Synthetic Opioid Overdose 3.2 Synthetic Opioid Overdose Gravity 3.3 Heroin Overdose 3.4 Meth Overdose 3.5 Cocaine Overdose", " Chapter 3 Mapping Variables Prior to running analyses, it is of interest to map out some variables to see how they distribute across the United States. 3.1 Synthetic Opioid Overdose 3.2 Synthetic Opioid Overdose Gravity 3.3 Heroin Overdose 3.4 Meth Overdose 3.5 Cocaine Overdose "],
["linreg.html", "Chapter 4 Linear Regression 4.1 In This Section 4.2 Imputation and Transformation 4.3 Neighboring Counties 4.4 A Simple Regression Model 4.5 A Multiple Regression Model 4.6 In Conclusion", " Chapter 4 Linear Regression 4.1 In This Section We want to see how effectively we can predict 2017 county-level synthetic opioid death rates using a simple linear regression approach. 4.2 Imputation and Transformation For some of our potential variables, we want to impute some missing values. For a few, as well, such as population density, we also want to log transform them. 4.3 Neighboring Counties We also want to generate a few additional variables that articulate the impact of synthetic opioid on neighboring counties. While we previously generated gravity variables, these are a function of both a county’s death rate and their neighbors. We want to generate variable(s) which simply articulate neighboring county rates. Here we create two new variables, one which measures the highest synthetic opioid overdose death rate of a county’s neighbors (continuous) and a second variable which measures (T/F) if any of a county’s neighbors exceed a certain threshold. 4.4 A Simple Regression Model 4.4.1 Defining Our Initial Regression Equation To begin, we start with a very simple model. We presume that the previous years synthetic opioid death rate will be highly predictive of the next year. We imagine that annual changes will be a function of time (as the epidemic has spread, the dynamics of the epidemic have changed) as well as the proximity of the epidemic. As such, we have included both year (continuous) and whether a neighbor had a death rate of 10 or more the previous year (T/F) as interaction terms. 4.4.2 Running the Model and Predicting So, first we need our training data. Essentially, our goal is to see if we can use 2016 county-level data to predict 2017 synthetic opioid death rates. So our training data will be all data prior to this. We will train a linear regression model on this data. Then we will use the model on the 2016 dataset to predict 2017 synthetic death rate. 4.4.3 Evaluating Model Performance 4.4.3.1 Continuous Metrics First, we want to see how well the model did at predicting the 2017 synthetic opioid crude deat rate. Here we present a series of metrics which reflect on the performance. ## R Squared RMSE MAE Pearson&#39;s R Spearman&#39;s rho ## 1 0.6449826 4.979847 2.446574 0.8278455 0.9015019 4.4.3.2 Categorical Metrics We predicted a continuous outcome, but it is of interest to simply ask if our model correctly identified counties whose death rate exceeded a certain threshold. For example, it may be of interest to see how well our model identified counties whose deeath rate exceeded 10 per 100,000. The following code calculates this, identifying true positives, true negatives, false positives, false negatives, and accompanying statistics of accuracy. ## ## FALSE TRUE ## FALSE 2330 422 ## TRUE 35 355 ## True Positives False Positives True Negatives False Negatives PPV NPV Senisitivity Specificity Accuracy ## 1 355 422 2330 35 0.4568855 0.9852008 0.9102564 0.846657 0.8545512 4.5 A Multiple Regression Model 4.5.1 Defining Our Initial Regression Equation Now, it is also of interest to see if including a series of covariates to our model may improve performance. For starters, we are just going to throw a bunch in and see. Then we will replicate what we did for the simple model. 4.5.2 Running the Model and Predicting So, first we need our training data. Essentially, our goal is to see if we can use 2016 county-level data to predict 2017 synthetic opioid death rates. So our training data will be all data prior to this. We will train a linear regression model on this data. Then we will use the model on the 2016 dataset to predict 2017 synthetic death rate. 4.5.3 Evaluating Model Performance 4.5.3.1 Continuous Metrics First, we want to see how well the model did at predicting the 2017 synthetic opioid crude deat rate. Here we present a series of metrics which reflect on the performance. ## R Squared RMSE MAE Pearson&#39;s R Spearman&#39;s rho ## 1 0.6854001 4.6387 2.005406 0.830342 0.9051792 4.5.3.2 Categorical Metrics We predicted a continuous outcome, but it is of interest to simply ask if our model correctly identified counties whose death rate exceeded a certain threshold. For example, it may be of interest to see how well our model identified counties whose deeath rate exceeded 10 per 100,000. The following code calculates this, identifying true positives, true negatives, false positives, false negatives, and accompanying statistics of accuracy. ## ## FALSE TRUE ## FALSE 2544 208 ## TRUE 40 350 ## True Positives False Positives True Negatives False Negatives PPV NPV Senisitivity Specificity Accuracy ## 1 350 208 2544 40 0.6272401 0.9845201 0.8974359 0.9244186 0.9210694 4.6 In Conclusion We see (when looking at our categorical outcomes) that the simple model performs rather well! Identifying a majority of the actual locations where the synthetic opioid death rate was at higher levels. We see though, that when we incorporate covariates, the false positive count is cut in half, indicating much much better performance overall. As well, continuous metrics indicate the inclusion of covariates improves model performance. "],
["otherML.html", "Chapter 5 Other Regression Strategies 5.1 Random Forest", " Chapter 5 Other Regression Strategies A question of interest is whether or not some other commonly used regression techniques perform better than linear regression. Here we examine this. 5.1 Random Forest A commonly used approach is random forest. Let us replicate everything we did with linear regression. 5.1.1 Defining Our Initial Regression Equation Now, it is also of interest to see if including a series of covariates to our model may improve performance. For starters, we are just going to throw a bunch in and see. Then we will replicate what we did for the simple model. 5.1.2 Running the Model and Predicting So, first we need our training data. Essentially, our goal is to see if we can use 2016 county-level data to predict 2017 synthetic opioid death rates. So our training data will be all data prior to this. We will train a linear regression model on this data. Then we will use the model on the 2016 dataset to predict 2017 synthetic death rate. 5.1.3 Evaluating Model Performance 5.1.3.1 Continuous Metrics First, we want to see how well the model did at predicting the 2017 synthetic opioid crude deat rate. Here we present a series of metrics which reflect on the performance. ## R Squared RMSE MAE Pearson&#39;s R Spearman&#39;s rho ## 1 0.6521824 4.877551 1.937538 0.8092943 0.9208151 5.1.3.2 Categorical Metrics We predicted a continuous outcome, but it is of interest to simply ask if our model correctly identified counties whose death rate exceeded a certain threshold. For example, it may be of interest to see how well our model identified counties whose deeath rate exceeded 10 per 100,000. The following code calculates this, identifying true positives, true negatives, false positives, false negatives, and accompanying statistics of accuracy. ## ## FALSE TRUE ## FALSE 2566 186 ## TRUE 51 339 ## True Positives False Positives True Negatives False Negatives PPV NPV Senisitivity Specificity Accuracy ## 1 339 186 2566 51 0.6457143 0.980512 0.8692308 0.9324128 0.9245703 "]
]
>>>>>>> 96a2b07c4e47453d536b37aeb9eaf1906d39a782
